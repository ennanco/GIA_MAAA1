{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513829d0",
   "metadata": {},
   "source": [
    "# Reducción de la dimensionalidad\n",
    "\n",
    "Tal como se ha comentado en las clases teóricas, uno de los puntos más importantes a la hora de afrontar probelmas, especialmente cuando tienen una alta dimensionalidad, es la reducción de dichas dimensiones con algunas de las técnicas enunciadas en clase. \n",
    "\n",
    "## Instalación\n",
    "El primer paso es comprobar que todos los paquetes necesarios están disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5191d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"ScikitLearn\")\n",
    "Pkg.add(\"RDatasets\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539a6cc",
   "metadata": {},
   "source": [
    "## Importación de dependencias\n",
    "Este no pretende ser un ejemplo exhaustivo de como realizar cualquier reducción si no un mero ejemplo. Por ello, está apoyado por el uso de la librería ScikitLearn que es un wrapper de la versión en Python de la misma. Es posible también usar otros frameworks com MLJ pero la integración de algunas de las técnicas como LLE o Isomap no está soportadas y deberían de implementarse.\n",
    "Por todo lo anterior a continuación importaremos las librerías y modulos que nos hacen falta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e416f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ScikitLearn\n",
    "using ScikitLearn.Pipelines: Pipeline\n",
    "using ScikitLearn.CrossValidation: train_test_split\n",
    "@sk_import feature_selection: (SelectKBest, f_classif)\n",
    "@sk_import preprocessing: (MinMaxScaler, LabelEncoder)\n",
    "@sk_import decomposition: (PCA, FastICA)\n",
    "@sk_import discriminant_analysis: LinearDiscriminantAnalysis\n",
    "@sk_import manifold: (Isomap, LocallyLinearEmbedding)\n",
    "@sk_import linear_model: LogisticRegression\n",
    "\n",
    "using RDatasets\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc89bd",
   "metadata": {},
   "source": [
    "También a modo de ejemplo vamos a importar el problema de las flores Iris, así como transformarlo para usarlo con un conjunto de entrenamiento y otro de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa917955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset Iris\n",
    "iris = dataset(\"datasets\", \"iris\")\n",
    "X = Matrix(iris[:, 1:4])\n",
    "y = string.(iris[:, 5])  # Convertir la variable objetivo en un vector de Strings\n",
    "\n",
    "# Convertir la variable objetivo en codificación numérica\n",
    "y = fit_transform!(LabelEncoder(), y)\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac7795",
   "metadata": {},
   "source": [
    "### Definir las técnicas de reducción que se van a emplear\n",
    "En este caso nos centraremso en transformaciones que están incluidas en ScikitLearn si bien se podrían usar otras. En concreto se van a emplear PCA, ICA, LDA, ISomap y LLE. Recuerde que si bien en este caso IsoMap y LLE se emplean con la clasificación su función es la de la representación dado que son transformaciones no lineales sin vuelta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un diccionario con las técnicas de reducción de dimensionalidad\n",
    "techniques = Dict(\n",
    "    \"Filtrado\"=> SelectKBest(score_func=f_classif, k=2),\n",
    "    \"PCA\" => PCA(n_components=2),\n",
    "    \"ICA\" => FastICA(n_components=2),\n",
    "    \"LDA\" => LinearDiscriminantAnalysis(n_components=2),\n",
    "    \"Isomap\" => Isomap(n_components=2),\n",
    "    \"LLE\" => LocallyLinearEmbedding(n_components=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ba935",
   "metadata": {},
   "source": [
    "Una vez definido un diccionario con dichas técnicas, el siguiente paso es usarlo para definir diferentes *Pipelines* y comprobar las diferencias entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e392be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamiento de resultados\n",
    "results = DataFrame(Technique = String[], Accuracy = Float64[])\n",
    "\n",
    "# Iterar sobre las técnicas\n",
    "for (name, reducer) in techniques\n",
    "    # Crear el pipeline: estandarización + reducción dimensional + regresión logística\n",
    "    model = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()),   # Estandarización de los datos\n",
    "        (\"reducer\", reducer),           # Reducción de dimensionalidad\n",
    "        (\"classifier\", LogisticRegression())  # Modelo de clasificación\n",
    "    ])\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    fit!(model, X_train, y_train)\n",
    "    \n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = predict(model, X_test)\n",
    "    \n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = sum(y_pred .== y_test) / length(y_test)\n",
    "    \n",
    "    # Almacenar los resultados\n",
    "    push!(results, (name, accuracy))\n",
    "    \n",
    "    # Mostrar resultados parciales\n",
    "    println(\"Técnica: $name, Precisión: $accuracy\")\n",
    "end\n",
    "\n",
    "# Mostrar resultados finales\n",
    "println(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa1f25e",
   "metadata": {},
   "source": [
    "# Representación\n",
    "\n",
    "Por último vamos a representar el espacio de entrada de todos los conjuntos con su correspondiente transformación. Para este punto haremos uso de una función auxiliar y el paquete `Plots`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4212af",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "# Generar scatterplots de las transformaciones\n",
    "function plot_transformed_data(name::String, reducer, X, y)\n",
    "    # Aplicar la reducción de dimensionalidad\n",
    "    X_reduced = fit_transform!(reducer, X, y)\n",
    "    \n",
    "    # Crear el scatterplot\n",
    "    p = scatter(X_reduced[:, 1], X_reduced[:, 2], group=y, legend=:topright, title=name,\n",
    "                xlabel=\"Componente 1\", ylabel=\"Componente 2\", markersize=5)\n",
    "    return p\n",
    "end\n",
    "\n",
    "# Crear los scatterplots en una cuadrícula\n",
    "plot_layout = @layout [a b c; d e f]\n",
    "plots = [plot_transformed_data(name, reducer, X, y) for (name, reducer) in techniques]\n",
    "\n",
    "# Mostrar todos los scatterplots en una cuadrícula\n",
    "plot(plots..., layout=plot_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119233a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

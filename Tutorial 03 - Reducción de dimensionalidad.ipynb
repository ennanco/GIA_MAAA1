{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513829d0",
   "metadata": {},
   "source": [
    "# Reducción de la dimensionalidad\n",
    "\n",
    "En muchos problemas de aprendizaje automático, especialmente aquellos con un gran número de variables o características, es fundamental reducir la dimensionalidad del conjunto de datos.  \n",
    "Este proceso permite simplificar el modelo, mejorar la interpretabilidad y, en muchos casos, aumentar el rendimiento y la eficiencia del aprendizaje.\n",
    "\n",
    "En este notebook se ilustran distintas técnicas de reducción de dimensionalidad implementadas en Julia, utilizando principalmente el framework **MLJ**, que ofrece una interfaz unificada para el entrenamiento y evaluación de modelos.\n",
    "\n",
    "## Instalación\n",
    "Antes de comenzar, se recomienda verificar que todas las dependencias necesarias estén correctamente instaladas en el entorno de trabajo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5191d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add([\"MLJ\",\n",
    "        \"MLJModels\",\n",
    "        \"MLJModelInterface\",\n",
    "        \"MultivariateStats\",\n",
    "        \"HypothesisTests\",\n",
    "        \"RDatasets\",\n",
    "        \"DataFrames\",\n",
    "        \"CategoricalArrays\",\n",
    "        \"StatsBase\",\n",
    "        \"Plots\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539a6cc",
   "metadata": {},
   "source": [
    "## Importación de dependencias\n",
    "\n",
    "Este notebook no pretende ser un ejemplo exhaustivo de todas las posibles técnicas de reducción de dimensionalidad, sino una guía práctica centrada en el uso de **MLJ** y algunas de sus extensiones más comunes.  \n",
    "\n",
    "Cabe destacar que ciertas técnicas, como *Isomap* o *Locally Linear Embedding (LLE)*, no están aún integradas directamente en MLJ y requieren la creación de *wrappers* específicos para su uso dentro de este framework. Esto ya fue cubierto en un notebook anterior y se le deja a los y las estudiantes para que lo exploren\n",
    "\n",
    "A continuación, se importan las librerías y módulos necesarios para ejecutar los ejemplos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e416f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "using MLJBase\n",
    "using MLJTransforms\n",
    "using MLJModelInterface\n",
    "using RDatasets\n",
    "using MultivariateStats\n",
    "using HypothesisTests\n",
    "using DataFrames\n",
    "using CategoricalArrays\n",
    "using StatsBase\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc89bd",
   "metadata": {},
   "source": [
    "## Conjunto de datos: Iris\n",
    "\n",
    "Como ejemplo práctico, utilizaremos el clásico conjunto de datos **Iris**, ampliamente empleado en tareas de clasificación y reducción de dimensionalidad.  \n",
    "\n",
    "Dividiremos el conjunto en dos partes: un conjunto de **entrenamiento** y otro de **prueba**, con el fin de evaluar el comportamiento de las diferentes técnicas de reducción en datos no vistos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa917955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset Iris\n",
    "iris = dataset(\"datasets\", \"iris\")\n",
    "y, X = unpack(iris, ==(:Species)); ## Un vector y una tabla resultante\n",
    "\n",
    "# === División en entrenamiento y prueba ===\n",
    "# 70% entrenamiento, 30% test, con semilla reproducible\n",
    "idx_train, idx_test = partition(eachindex(y), 0.7, rng=42); \n",
    "\n",
    "(X_train, X_test), (y_train, y_test) = (X[idx_train, :], X[idx_test, :]), (y[idx_train], y[idx_test]);\n",
    "\n",
    "@info \"Train dataset $(size(X_train)) -> $(length(y_train))\"\n",
    "@info \"Test dataset  $(size(X_test)) -> $(length(y_test))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac7795",
   "metadata": {},
   "source": [
    "#### Definición de las técnicas de reducción\n",
    "\n",
    "En esta sección definiremos las principales técnicas de reducción que se van a emplear.  \n",
    "Nos centraremos en aquellas disponibles en las librerías compatibles con MLJ —como PCA, ICA y LDA— aunque es posible incorporar muchas otras.\n",
    "\n",
    "Las técnicas de tipo *manifold learning*, como **Isomap** o **LLE**, son transformaciones no lineales útiles para la representación y visualización de datos en espacios de menor dimensión, si bien no siempre permiten una reconstrucción inversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero es necesario cargarlas librerías\n",
    "PCA = @load PCA pkg=MultivariateStats add=true\n",
    "ICA = @load ICA pkg=MultivariateStats\n",
    "LDA = @load LDA pkg=MultivariateStats\n",
    "\n",
    "\n",
    "# Definimos un diccionario con las técnicas de reducción de dimensionalidad\n",
    "techniques=Dict(\n",
    "    \"PCA\" => PCA(maxoutdim=2),\n",
    "    \"ICA\" => ICA(outdim=2, maxiter=500, tol=1e-1, do_whiten=true),\n",
    "    \"LDA\" => LDA(outdim=2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6408c41",
   "metadata": {},
   "source": [
    "## Filtrado de características\n",
    "\n",
    "Además de las técnicas de proyección, es posible aplicar **métodos de filtrado** para la selección de características más relevantes.  \n",
    "Entre ellos destacan los basados en medidas estadísticas como *Pearson*, *ANOVA* o *Spearman*.  \n",
    "\n",
    "En este ejemplo se mostrará cómo integrar un filtro ANOVA dentro del flujo de trabajo, empleando código similar al visto en el *Tutorial 2*.  \n",
    "Estos métodos resultan útiles para eliminar atributos redundantes antes de aplicar técnicas de reducción más complejas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using HypothesisTests\n",
    "\n",
    "# ===============================\n",
    "# ANOVA SelectKBest Filter\n",
    "# ===============================\n",
    "# Definir la estructura del modelo\n",
    "mutable struct ANOVAFilter <: MLJModelInterface.Supervised\n",
    "    k::Int\n",
    "end\n",
    "\n",
    "# Constructor con argumentos por nombre (estilo MLJ)\n",
    "ANOVAFilter(; k::Int=2) = ANOVAFilter(k)\n",
    "\n",
    "# Se hace la importación de las funciones necesarias para poder sobrecargarlas\n",
    "import MLJModelInterface: fit, transform, input_scitype, target_scitype, output_scitype\n",
    "\n",
    "# Definir la función fit\n",
    "function fit(model::ANOVAFilter, verbosity::Int, X, y)\n",
    "    # Convertir X a matriz y asegurarse que es Float64\n",
    "    Xmat = Float64.(MLJBase.matrix(X))\n",
    "    \n",
    "    # Convertir y a vector numérico si es categórico\n",
    "    y_numeric = y isa CategoricalVector ? Int.(levelcode.(y)) : Int.(y)\n",
    "    \n",
    "    # Calcular F-statistics usando HypothesisTests\n",
    "    n_features = size(Xmat, 2)\n",
    "    fstats = zeros(Float64, n_features)\n",
    "    \n",
    "    for j in 1:n_features\n",
    "        feature = Xmat[:, j]\n",
    "        \n",
    "        # Agrupar datos por clase\n",
    "        classes = unique(y_numeric)\n",
    "        groups = [feature[y_numeric .== c] for c in classes]\n",
    "        \n",
    "        # Filtrar grupos vacíos\n",
    "        groups = filter(g -> length(g) > 0, groups)\n",
    "        \n",
    "        if length(groups) < 2\n",
    "            fstats[j] = 0.0\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "        try\n",
    "            # Crear test ANOVA\n",
    "            test = OneWayANOVATest(groups...)\n",
    "            \n",
    "            # Calcular F-statistic manualmente desde los campos disponibles\n",
    "            MSt = test.SStᵢ / test.DFt  # Mean square treatment (between)\n",
    "            MSe = test.SSeᵢ / test.DFe  # Mean square error (within)\n",
    "            \n",
    "            fstats[j] = MSt / MSe\n",
    "        catch e\n",
    "            # Si hay algún error en el cálculo, asignar 0\n",
    "            fstats[j] = 0.0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Seleccionar top k features con mayor F-statistic\n",
    "    k_actual = min(model.k, n_features)\n",
    "    idxs = sortperm(fstats, rev=true)[1:k_actual]\n",
    "    \n",
    "    # Guardar los nombres de las columnas originales\n",
    "    feature_names = collect(Tables.columnnames(X))\n",
    "    selected_names = [feature_names[i] for i in idxs]\n",
    "    \n",
    "    # IMPORTANTE: fitresult debe contener la info necesaria para transform\n",
    "    fitresult = (idxs=idxs, selected_names=selected_names)\n",
    "    cache = nothing\n",
    "    report = (fstats=fstats, idxs=idxs, selected_features=selected_names)\n",
    "    \n",
    "    return fitresult, cache, report\n",
    "end\n",
    "\n",
    "# Definir la función transform\n",
    "function transform(model::ANOVAFilter, fitresult, X)\n",
    "    # Convertir X a matriz\n",
    "    Xmat = MLJBase.matrix(X)\n",
    "    \n",
    "    # Seleccionar columnas usando fitresult (no cache)\n",
    "    X_selected = Xmat[:, fitresult.idxs]\n",
    "    \n",
    "    # Convertir de vuelta a tabla con nombres apropiados\n",
    "    return MLJBase.table(X_selected, names=fitresult.selected_names)\n",
    "end\n",
    "\n",
    "# Definir los tipos de entrada y salida\n",
    "input_scitype(::Type{<:ANOVAFilter}) = Table(Continuous)\n",
    "target_scitype(::Type{<:ANOVAFilter}) = AbstractVector{<:Finite}\n",
    "output_scitype(::Type{<:ANOVAFilter}) = Table(Continuous)\n",
    "\n",
    "\n",
    "techniques[\"Filtrado (ANOVA)\"] = ANOVAFilter(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394dd59",
   "metadata": {},
   "source": [
    "## Construcción de *Pipelines*\n",
    "\n",
    "Una vez definidas las distintas técnicas, el siguiente paso consiste en utilizarlas para construir *pipelines* que combinen varias etapas del flujo de trabajo: estandarización, reducción de dimensionalidad y clasificación.  \n",
    "\n",
    "Esto permitirá comparar fácilmente el rendimiento de cada combinación y observar las diferencias entre los distintos enfoques.\n",
    "\n",
    "Un elemento clave en este punto es que se están mezclando dos tipos de técnicas, supervisadas y no supervisadas, como transformadores. Esto de primeras si se usa la clase *Pipeline* dará un error, por lo que será necesario hacer el pipeline en dos etapas. Si no se usasen los transformadores LDA e ANOVA se podría integrar todo en un *pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d22dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ, DataFrames, RDatasets, Statistics\n",
    "\n",
    "# Cargar modelo clasificición y estandarizador\n",
    "Standardizer = @load Standardizer pkg=MLJModels\n",
    "LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels\n",
    "\n",
    "\n",
    "# Técnicas que viene definidas de las celdas anteriores\n",
    "#techniques = Dict(\n",
    "#    \"PCA\" => PCA(maxoutdim=2),\n",
    "#    \"ICA\" => ICA(outdim=2, maxiter=500, tol=1e-1, do_whiten=true),\n",
    "#    \"LDA\" => LDA(outdim=2),\n",
    "#    \"ANOVA_k2\" => ANOVAFilter(k=2)\n",
    "#)\n",
    "\n",
    "# Definidión Resultados\n",
    "results = DataFrame(Technique=String[], Accuracy=Float64[])\n",
    "\n",
    "# Estandarizar los datos\n",
    "std_model = Standardizer()\n",
    "std_mach = machine(std_model, X_train)\n",
    "fit!(std_mach)\n",
    "Xs_train = transform(std_mach, X_train)\n",
    "Xs_test  = transform(std_mach, X_test)\n",
    "\n",
    "machines = Dict()\n",
    "\n",
    "# Comprobar cada técnica de reducción\n",
    "for (name, reducer) in techniques\n",
    "    println(\"\\nEntrenando con: $name (dos etapas)\")\n",
    "    try\n",
    "        # --- Etapa 1: Reducción --- \n",
    "        \n",
    "        if MLJModelInterface.is_supervised(reducer)\n",
    "            # Caso supervisado en el que se usa X e y\n",
    "            machines[name] = machine(reducer, Xs_train, y_train)\n",
    "        else\n",
    "            # Caso no supervisado en el que se usa solo X\n",
    "            machines[name] = machine(reducer, Xs_train)\n",
    "        end\n",
    "        fit!(machines[name])\n",
    "        # Realizar las transformaciones\n",
    "        Xredudeced_train = transform(machines[name], Xs_train)\n",
    "        Xreduced_test  = transform(machines[name], Xs_test)\n",
    "\n",
    "        # --- Etapa 2: Clasificador ---\n",
    "        clf = LogisticClassifier()\n",
    "        clf_mach = machine(clf, Xredudeced_train, y_train)\n",
    "        fit!(clf_mach)\n",
    "        y_pred = predict_mode(clf_mach, Xreduced_test)\n",
    "\n",
    "        acc = mean(y_pred .== y_test)\n",
    "        push!(results, (name, acc))\n",
    "        println(\"✓ Precisión: \", round(acc, digits=4))\n",
    "\n",
    "    catch e\n",
    "        println(\"✗ Error en $name: $e\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# Imprimir los resultados para todos los métodos probados\n",
    "sort!(results, :Accuracy, rev=true)\n",
    "println(\"\\n\", \"=\"^50)\n",
    "println(\"RESULTADOS FINALES\")\n",
    "println(\"=\"^50)\n",
    "for row in eachrow(results)\n",
    "    println(\"$(rpad(row.Technique, 15)) → $(round(row.Accuracy * 100, digits=2))%\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ba935",
   "metadata": {},
   "source": [
    "Una vez definido un diccionario con dichas técnicas, el siguiente paso es usarlo para definir diferentes *Pipelines* y comprobar las diferencias entre ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa1f25e",
   "metadata": {},
   "source": [
    "# Representación visual\n",
    "\n",
    "Por último, representaremos los datos transformados por cada una de las técnicas de reducción de dimensionalidad.  \n",
    "Para ello haremos uso de una función auxiliar y del paquete **Plots**, que nos permitirá generar gráficos bidimensionales donde se puedan apreciar las separaciones entre clases tras la transformación del espacio original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4212af",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "# Generar scatterplots de las transformaciones\n",
    "function plot_transformed_data(name::String, reducer, X, y)\n",
    "    # Ajustar reductor\n",
    "    if MLJModelInterface.is_supervised(reducer)\n",
    "        mach_red = machine(reducer, Xs, y)\n",
    "    else\n",
    "        mach_red = machine(reducer, Xs)\n",
    "    end\n",
    "    fit!(mach_red, verbosity=0)\n",
    "\n",
    "    X_reduced = transform(mach, X)\n",
    "    \n",
    "    # Crear el scatterplot\n",
    "    p = scatter(X_reduced[:, 1], X_reduced[:, 2], group=y, legend=:topright, title=name,\n",
    "                xlabel=\"Componente 1\", ylabel=\"Componente 2\", markersize=5)\n",
    "    return p\n",
    "end\n",
    "\n",
    "#Preparar todos los datos con el Standadizer\n",
    "std_mach = machine(std_model, X)\n",
    "fit!(std_mach, verbosity=0)\n",
    "Xs = transform(std_mach, X)\n",
    "\n",
    "# Crear los scatterplots en una cuadrícula\n",
    "plot_layout = @layout [a b; c d]\n",
    "plots = [plot_transformed_data(name, reducer, Xs, y) for (name, reducer) in techniques]\n",
    "\n",
    "# Mostrar todos los scatterplots en una cuadrícula\n",
    "plot(plots..., layout=plot_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0687f51d",
   "metadata": {},
   "source": [
    "## Ejercicio propuesto\n",
    "\n",
    "Como ejercicio adicional, se propone incorporar otras técnicas de reducción, como **t-SNE**, **Isomap** o **LLE**.  \n",
    "Aunque algunas de ellas no están integradas directamente en MLJ, pueden utilizarse mediante *wrappers* o implementaciones externas.  \n",
    "Estas técnicas son especialmente útiles para la **visualización** de datos en espacios de baja dimensión y pueden complementar las vistas obtenidas con los métodos incluidos en este notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659fdf3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

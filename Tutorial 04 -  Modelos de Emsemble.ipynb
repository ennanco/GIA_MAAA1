{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dd4668",
   "metadata": {},
   "source": [
    "# Modelos *Ensemble*\n",
    "\n",
    "Una de las tendencias más recientes en el ámbito del modelado de inteligencia artificial puede resumirse bajo la expresión **“el conocimiento del conjunto o de la multitud”**. Esta formulación, relativamente familiar, hace referencia al empleo de una multiplicidad de modelos denominados *débiles* en el contexto de un meta-clasificador. El propósito de este enfoque es generar un modelo *fuerte* a partir del conocimiento extraído por dichos modelos *débiles*.  \n",
    "\n",
    "Por ejemplo, aunque se detallará con mayor profundidad más adelante, en un **Random Forest** se desarrollan múltiples Árboles de Decisión de menor complejidad. La combinación de estos en el bosque aleatorio permite alcanzar un rendimiento superior al de cualquiera de los modelos individuales considerados por separado. Los modelos que se construyen de esta manera, ya sea en forma de meta-clasificadores o meta-regresores, se denominan de forma genérica **modelos *Ensemble***.  \n",
    "\n",
    "Conviene destacar que estos modelos no se limitan exclusivamente al uso de árboles de decisión, sino que pueden estar conformados por cualquier tipo de modelo de aprendizaje automático previamente estudiado. Incluso es posible construir **modelos mixtos**, en los que no todos los submodelos se hayan obtenido mediante el mismo procedimiento, sino a través de la combinación de diversas técnicas, tales como *k*-NN, *SVM*, entre otras.  \n",
    "\n",
    "De este modo, el **primer criterio para clasificar los modelos *Ensemble*** consiste en determinar si se trata de modelos **homogéneos** o **heterogéneos**. No obstante, este no es el único criterio de clasificación. En esta unidad se abordarán diferentes estrategias para la generación de modelos y para su combinación posterior. Asimismo, se analizarán en detalle dos de las técnicas más representativas dentro de los modelos *Ensemble*: **Random Forest** , **_XGBoost_** y otras de las últimas tendencias como **LightGBM** y **CatBoost**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e861d",
   "metadata": {},
   "source": [
    "En primer lugar, asegúrate de que los paquetes necesarios estén instalados. Por tanto, esta celda debe ejecutarse únicamente la **primera vez**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b736500",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Asegúrate de que los paquetes requeridos estén disponibles  \n",
    "#(descomenta las líneas correspondientes para instalarlos, si es necesario).\n",
    "Pkg.add([\n",
    "    \"MLJ\", \n",
    "    \"MLJBase\", \n",
    "    \"MLJModels\", \n",
    "    \"MLJEnsembles\", \n",
    "    \"MLJLinearModels\", \n",
    "    \"DecisionTree\", \n",
    "    \"MLJDecisionTreeInterface\", \n",
    "    \"NaiveBayes\", \n",
    "    \"EvoTrees\", \n",
    "    \"CategoricalArrays\", \n",
    "    \"Random\",\n",
    "    \"LIBSVM\",           \n",
    "    \"Plots\",            \n",
    "    \"MLJModelInterface\", \n",
    "    \"CSV\",              \n",
    "    \"DataFrames\",       \n",
    "    \"UrlDownload\",      \n",
    "    \"XGBoost\"    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "\n",
    "A diferencia de los primeros tutoriales, en los que se empleó el problema de las flores *iris* como referencia, en este tutorial utilizaremos un caso distinto. El problema también se encuentra disponible en el repositorio UCI. Aunque se trata igualmente de un conjunto de datos de pequeño tamaño, el número de variables aumenta de forma significativa, lo que nos permitirá realizar un análisis más amplio.  \n",
    "\n",
    "En concreto, se trata de un problema clásico de aprendizaje automático conocido informalmente como **¿Roca o Mina?** (*Rock or Mine?*). Este conjunto de datos contiene 111 patrones correspondientes a rocas y 97 a minas submarinas (simuladas como cilindros metálicos). Cada patrón está formado por **60 medidas numéricas** que representan una sección de las secuencias de sonar. Estos valores se encuentran ya en el rango de 0.0 a 1.0, aunque resulta recomendable normalizarlos por seguridad. Las medidas reflejan el valor energético de diferentes rangos de longitud de onda durante un determinado periodo temporal.  \n",
    "\n",
    "En este proceso vamos a emplear un par de paquetes nuevos, concretamente [DataFrames.jl](https://juliaai.github.io/DataScienceTutorials.jl/data/dataframe/) y [UrlDownload.jl](https://github.com/Arkoniak/UrlDownload.jl).  \n",
    "Por tanto, lo primero que debemos hacer es asegurarnos de que los paquetes estén correctamente instalados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"UrlDownload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad05475",
   "metadata": {},
   "source": [
    "A continuación, los datos se descargarán en caso de que no estén disponibles localmente.  \n",
    "Para ello, puede emplearse el siguiente fragmento de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "using UrlDownload\n",
    "using DataFrames\n",
    "using CSV\n",
    "using CategoricalArrays\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "data = urldownload(url, true, format=:CSV, header=false) |> DataFrame\n",
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebf504",
   "metadata": {},
   "source": [
    "Como puede observarse en la línea anterior, hemos descargado los datos y los hemos canalizado mediante el operador `|>` hacia la función `DataFrame`.  \n",
    "Esto permite crear una estructura similar a una tabla de base de datos, lo cual resulta especialmente conveniente para comprobar la existencia de valores ausentes o analizar los rangos de las distintas variables.  \n",
    "\n",
    "De hecho, esta biblioteca facilita notablemente la gestión de valores perdidos, al proporcionar funciones que permiten tanto completar como eliminar las muestras con medidas no válidas.  \n",
    "No obstante, el conjunto de datos es demasiado extenso para visualizar todas las variables en el informe de salida. Si realizamos algunas consultas específicas, podemos comprobar que **no existen valores ausentes**. Además, ninguna variable supera el valor de 1.0, aunque algunas de ellas no están completamente normalizadas.  \n",
    "\n",
    "Una estructura análoga puede encontrarse en otros lenguajes de programación, como **R** o **Python**.  \n",
    "\n",
    "Como ejemplo de este proceso, añadiremos una columna adicional con el fin de **convertir en categórica la última columna (la número 60)**, que contiene una **M** para cada muestra correspondiente a una mina y una **R** para cada muestra correspondiente a una roca.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a07ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "insertcols!(data, :Mine => data[:, 61].==\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa393f",
   "metadata": {},
   "source": [
    "Una vez que los datos se han cargado en el `DataFrame` para su verificación y se ha aplicado cualquier posible proceso de preparación, es necesario transformarlos para su utilización en los modelos.  \n",
    "\n",
    "Al igual que en los tutoriales anteriores, los datos deben convertirse a una **forma matricial**, tal como se muestra a continuación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ea8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Matrix(data[!, 1:60]);\n",
    "output_data = data[!, :Mine];\n",
    "\n",
    "@assert input_data isa Matrix\n",
    "@assert output_data isa BitVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a148c7",
   "metadata": {},
   "source": [
    "Cabe destacar que, en un `DataFrame`, cuando se consulta un conjunto de filas, como en el caso de la variable `X`, el resultado obtenido es también un objeto de tipo `DataFrame`.  \n",
    "\n",
    "Por tanto, para poder aplicar las operaciones posteriores, es necesario utilizar la función `Matrix`, la cual convierte dicho resultado en una **matriz** sobre la que pueden ejecutarse las operaciones habituales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272d3b3",
   "metadata": {},
   "source": [
    "### Pregunta\n",
    "\n",
    "> ❓Ahora, los datos se han cargado y convertido a los tipos habituales. A continuación, deberías poder abordar la siguiente sección: realizar una partición del conjunto de datos en dos subconjuntos, **entrenamiento** y **prueba**, y aplicar la normalización correspondiente. Incluye el código en la sección siguiente para ejecutar ambas operaciones. *Consejo: debido a la preparación para los modelos de MLJ, lee las notas al final del documento.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_input, train_output, test_input, test_output = #TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbe5ef",
   "metadata": {},
   "source": [
    "## Línea base\n",
    "\n",
    "Como se ha mencionado, los *ensembles* son conjuntos de clasificadores “más débiles” que, al combinarse, permiten superar sus limitaciones individuales. Por ello, antes de abordar los *ensembles*, resulta necesario disponer de algunos **modelos de referencia** que posteriormente se integrarán en un **meta-clasificador**.\n",
    "\n",
    "En el ejemplo siguiente, se entrenan varios modelos sencillos implementados con la biblioteca `MLJ`:  \n",
    "- una **SVM** con **núcleo RBF**  \n",
    "- una **Regresión Lineal**  \n",
    "- un **Naïve Bayes**  \n",
    "- un **Árbol de Decisión**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b0a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using MLJ\n",
    "using MLJBase: accuracy\n",
    "\n",
    "# Cargar los modelos (tenga presente que si algunos no están instalados, MLJ le pedirá que los instale)\n",
    "SVC = @load ProbabilisticSVC pkg=LIBSVM\n",
    "LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels\n",
    "DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree\n",
    "GaussianNBClassifier = @load GaussianNBClassifier pkg=NaiveBayes\n",
    "\n",
    "#Definir los modelos base\n",
    "models = Dict(\n",
    "    \"SVM\" => SVC(),\n",
    "    \"LR\"  => LogisticClassifier(),\n",
    "    \"DT\"  => DecisionTreeClassifier(max_depth=4),\n",
    "    \"NB\"  => GaussianNBClassifier(),\n",
    ")\n",
    "\n",
    "base_models=  [ model for (name, model) in models]\n",
    "\n",
    "machines = Dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a595d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el entrenamiento de cada modelo y calculas los valores de test (accuracy)\n",
    "for (name, model) in models\n",
    "    machines[name] = machine(model, train_input, train_output) |> fit!\n",
    "    acc = MLJ.accuracy(predict_mode(machines[name], test_input), test_output)\n",
    "    println(\"$name: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ecb8c",
   "metadata": {},
   "source": [
    "## Combinación de modelos débiles en un *ensemble*\n",
    "\n",
    "A la hora de combinar los modelos, existen diversas estrategias que dependen de la tarea que se esté abordando, es decir, de si se trata de un problema de **clasificación** o de **regresión**. En este caso concreto nos centraremos en la clasificación; no obstante, para la regresión el procedimiento sería similar, aunque habría que tener en cuenta la naturaleza continua de los valores al combinar las salidas.\n",
    "\n",
    "En lo que respecta a la **combinación de clasificadores**, existen principalmente dos enfoques para integrar las salidas de varios modelos:  \n",
    "- **Votación mayoritaria** (*Majority Voting*), y  \n",
    "- **Votación mayoritaria ponderada**, también conocida como **Votación Suave** (*Soft Voting*).\n",
    "\n",
    "\n",
    "Como primer paso y dado que MLJ no dispone de una clase para este tipo de clasificaciones de manera nativa, vamos a definir una que soporte modelos heterogéneos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "using MLJBase\n",
    "using MLJModelInterface\n",
    "\n",
    "# ===================================================\n",
    "# DEFINICION del VOTINGCLASSIFIER compatible con MLJ\n",
    "# ===================================================\n",
    "\n",
    "\"\"\"\n",
    "    VotingClassifier <: Probabilistic\n",
    "\n",
    "Un clasificador *ensemble* que combina las predicciones de múltiples modelos base utilizando diferentes estrategias de votación.\n",
    "\n",
    "# Campos\n",
    "- `models::Vector{Probabilistic}`: Vector de modelos probabilísticos base que se combinarán.  \n",
    "- `voting::Symbol`: Estrategia de votación, que puede ser `:hard` (votación mayoritaria) o `:soft` (promedio de probabilidades).  \n",
    "- `weights::Union{Nothing, Vector{Float64}}`: Pesos opcionales para cada modelo. Si se establece como `nothing`, todos los modelos tendrán el mismo peso. Los pesos se normalizan automáticamente para que su suma sea 1.0.\n",
    "\n",
    "# Ejemplos\n",
    "```julia\n",
    "# Pesos iguales (por defecto)\n",
    "voting_clf = VotingClassifier(\n",
    "    models=[LogisticClassifier(), DecisionTreeClassifier()],\n",
    "    voting=:soft\n",
    ")\n",
    "\n",
    "# Pesos personalizados (se normalizan automáticamente)\n",
    "voting_clf = VotingClassifier(\n",
    "    models=[LogisticClassifier(), DecisionTreeClassifier(), RandomForestClassifier()],\n",
    "    voting=:hard,\n",
    "    weights=[5, 3, 2]  # Se normalizarán a [0.5, 0.3, 0.2]\n",
    ")\n",
    "mutable struct VotingClassifier <: Probabilistic   # Models must be probabilistic, inherited from MLJBase\n",
    "    models::Vector{Probabilistic}\n",
    "    voting::Symbol  # :hard or :soft\n",
    "    weights::Union{Nothing, Vector{Float64}}\n",
    "end\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    VotingClassifier(; models=Probabilistic[], voting=:hard, weights=nothing)\n",
    "Constructor del `VotingClassifier`.\n",
    "\n",
    "# Argumentos\n",
    "- `models::Vector{Probabilistic}=Probabilistic[]`: Modelos base que se combinarán.  \n",
    "- `voting::Symbol=:hard`: Estrategia de votación (`:hard` o `:soft`).  \n",
    "- `weights::Union{Nothing, Vector{<:Real}}=nothing`: Pesos asignados a cada modelo. Se normalizan automáticamente para que su suma sea 1.0.\n",
    "\n",
    "# Excepciones\n",
    "- `AssertionError`: Si el parámetro `voting` no es `:hard` ni `:soft`.  \n",
    "- `AssertionError`: Si la longitud del vector de pesos no coincide con el número de modelos.  \n",
    "- `AssertionError`: Si todos los pesos son cero o negativos.\n",
    "\"\"\"\n",
    "\n",
    "function VotingClassifier(; models=Probabilistic[], voting=:hard, weights=nothing)\n",
    "    @assert voting in [:hard, :soft] \"The only possible labels are :hard or :soft\"\n",
    "    \n",
    "    normalized_weights = nothing\n",
    "    if weights !== nothing\n",
    "        @assert length(weights) == length(models) \"Number of weights must match number of models\"\n",
    "        @assert all(w >= 0 for w in weights) \"All weights must be non-negative\"\n",
    "        \n",
    "        # Normalizar los pesos para sumar 1.0\n",
    "        normalized_weights = Float64.(weights) ./ sum(weights)\n",
    "    end\n",
    "    \n",
    "    return VotingClassifier(models, voting, normalized_weights)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    MLJModelInterface.fit(model::VotingClassifier, verbosity::Int, X, y)\n",
    "\n",
    "Entrena el `VotingClassifier` ajustando cada modelo base con los datos proporcionados.\n",
    "\n",
    "# Argumentos\n",
    "- `model::VotingClassifier`: Instancia del clasificador de votación.  \n",
    "- `verbosity::Int`: Nivel de verbosidad para el registro del proceso de entrenamiento.  \n",
    "- `X`: Características de entrenamiento (en formato de tabla).  \n",
    "- `y`: Variable objetivo de entrenamiento (vector categórico).\n",
    "\n",
    "# Retorna\n",
    "- `fitresults`: Vector de máquinas entrenadas (una por cada modelo base).  \n",
    "- `cache`: `nothing` (no se implementa almacenamiento en caché).  \n",
    "- `report`: Tupla con nombre que contiene información del entrenamiento (número de modelos, estrategia de votación y pesos normalizados).\n",
    "\"\"\"\n",
    "\n",
    "function MLJModelInterface.fit(model::VotingClassifier, verbosity::Int, X, y)\n",
    "    # Entrenar cada modelo base\n",
    "    fitresults = []\n",
    "    for base_model in model.models\n",
    "        model_copy = deepcopy(base_model)\n",
    "        mach = machine(model_copy, X, y)\n",
    "        fit!(mach, verbosity=0)\n",
    "        push!(fitresults, mach)\n",
    "    end\n",
    "    \n",
    "    # Guardar información necesaria para el reporte sobre el entrenamiento\n",
    "    cache = nothing\n",
    "    report = (n_models=length(model.models), voting=model.voting, weights=model.weights)\n",
    "    \n",
    "    return fitresults, cache, report\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    MLJModelInterface.predict_mode(model::VotingClassifier, fitresult, Xnew)\n",
    "\n",
    "Predice las etiquetas de clase utilizando **votación dura** (*hard voting*), es decir, votación mayoritaria con pesos opcionales.\n",
    "\n",
    "# Argumentos\n",
    "- `model::VotingClassifier`: Instancia del clasificador de votación.  \n",
    "- `fitresult`: Vector de máquinas entrenadas obtenido en la fase de ajuste.  \n",
    "- `Xnew`: Nuevos datos sobre los que se realizará la predicción.\n",
    "\n",
    "# Retorna\n",
    "- Vector categórico con las etiquetas de clase predichas, calculadas mediante votación mayoritaria (ponderada o no).\n",
    "\n",
    "# Detalles\n",
    "Cada modelo base emite un voto por una clase.  \n",
    "Si se han definido pesos, cada voto se multiplica por el peso correspondiente.  \n",
    "La clase con el mayor número de votos (ponderados) es seleccionada como predicción final.\n",
    "\"\"\"\n",
    "\n",
    "function MLJModelInterface.predict_mode(model::VotingClassifier, fitresult, Xnew)\n",
    "    machines = fitresult\n",
    "    \n",
    "    # Calcular las predicciones de cada modelo base\n",
    "    predictions = [predict_mode(mach, Xnew) for mach in machines]\n",
    "    \n",
    "    # Obtener todas las clases posibles\n",
    "    all_classes = unique(vcat([unique(p) for p in predictions]...))\n",
    "    n_samples = length(predictions[1])\n",
    "    n_models = length(machines)\n",
    "    \n",
    "    # Determinar los pesos (iguales si no se especifican)\n",
    "    weights = model.weights === nothing ? fill(1.0/n_models, n_models) : model.weights\n",
    "    \n",
    "    # Votación mayoritaria ponderada\n",
    "    ensemble_pred = Vector{eltype(predictions[1])}(undef, n_samples)\n",
    "    \n",
    "    for i in 1:n_samples\n",
    "        # Contar los votos ponderados para cada clase\n",
    "        vote_counts = Dict{eltype(predictions[1]), Float64}()\n",
    "        for class in all_classes\n",
    "            vote_counts[class] = 0.0\n",
    "        end\n",
    "        \n",
    "        for (j, pred) in enumerate(predictions)\n",
    "            vote_counts[pred[i]] += weights[j]\n",
    "        end\n",
    "        \n",
    "        # Seleccionar la clase con el mayor número de votos\n",
    "        ensemble_pred[i] = argmax(vote_counts)\n",
    "    end\n",
    "    \n",
    "    return categorical(ensemble_pred)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    MLJModelInterface.predict(model::VotingClassifier, fitresult, Xnew)\n",
    "\n",
    "Predice las probabilidades de clase utilizando la estrategia de votación especificada.\n",
    "\n",
    "# Argumentos\n",
    "- `model::VotingClassifier`: Instancia del clasificador de votación.  \n",
    "- `fitresult`: Vector de máquinas entrenadas obtenido durante el ajuste.  \n",
    "- `Xnew`: Nuevos datos sobre los que se realizarán las predicciones.\n",
    "\n",
    "# Retorna\n",
    "- Vector de distribuciones `UnivariateFinite` que representan las probabilidades de pertenencia a cada clase.\n",
    "\n",
    "# Detalles\n",
    "- Para la votación `:hard`: se devuelven predicciones deterministas encapsuladas en `UnivariateFinite` (con pesos opcionales).  \n",
    "- Para la votación `:soft`: se calculan las probabilidades promediando las distribuciones generadas por todos los modelos base, aplicando los pesos correspondientes.\n",
    "\"\"\"\n",
    "\n",
    "function MLJModelInterface.predict(model::VotingClassifier, fitresult, Xnew)\n",
    "    machines = fitresult\n",
    "    \n",
    "    result = if model.voting == :hard\n",
    "        # Para hard voting, devvuelve las predicciones tal cual\n",
    "        UnivariateFinite(predict_mode(model, fitresult, Xnew))\n",
    "    else\n",
    "        # Para soft voting, promedia las probabilidades con los pesos\n",
    "        all_predictions = [predict(mach, Xnew) for mach in machines]\n",
    "        \n",
    "        # Recupera la información de las clases\n",
    "        first_pred = all_predictions[1][1]\n",
    "        class_levels = MLJBase.classes(first_pred)\n",
    "        n_classes = length(class_levels)\n",
    "        n_samples = length(all_predictions[1])\n",
    "        n_models = length(machines)\n",
    "        \n",
    "        # Determina los pesos (iguales si no se especifican)\n",
    "        weights = model.weights === nothing ? fill(1.0/n_models, n_models) : model.weights\n",
    "        \n",
    "        # Calcula la media ponderada de las probabilidades\n",
    "        avg_probs = zeros(n_samples, n_classes)\n",
    "        for (model_idx, preds) in enumerate(all_predictions)\n",
    "            for i in 1:n_samples\n",
    "                for (j, level) in enumerate(class_levels)\n",
    "                    avg_probs[i, j] += weights[model_idx] * pdf(preds[i], level)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # Crea distribuciones `UnivariateFinite` con probabilidades promediadas de forma ponderada.\n",
    "        [UnivariateFinite(class_levels, avg_probs[i, :]) for i in 1:n_samples]\n",
    "    end\n",
    "    \n",
    "    return result\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Registro de metadatos del modelo para `VotingClassifier`.\n",
    "\n",
    "Especifica los tipos de entrada/salida y las capacidades para su integración con MLJ.\n",
    "\"\"\"\n",
    "MLJModelInterface.metadata_model(VotingClassifier,\n",
    "    input_scitype=Table(Continuous),\n",
    "    target_scitype=AbstractVector{<:Finite},\n",
    "    supports_weights=false,\n",
    "    load_path=\"VotingClassifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2b2cf",
   "metadata": {},
   "source": [
    "## Votación mayoritaria\n",
    "\n",
    "También conocida como *Hard Voting*, consiste, como su nombre sugiere, en seleccionar la opción más votada entre las predicciones emitidas por los distintos modelos. Cada modelo emite un voto o predicción determinista. La clase (o predicción) final es aquella que recibe **el mayor número de votos** o, en caso de regresión, **el valor medio** entre los resultados. Es equivalente a una “elección democrática” en la que cada modelo/experto dispone de un voto y gana la opción más votada. De este modo, el problema puede abordarse teniendo en cuenta diferentes resultados o puntos de vista.\n",
    "\n",
    "### Ejemplo\n",
    "\n",
    "Con 3 clasificadores que predicen un mismo patrón:\n",
    "\n",
    "- **SVM** predice: **Mina**  \n",
    "- **Regresión Logística** predice: **Roca**  \n",
    "- **Naive Bayes** predice: **Roca**\n",
    "\n",
    "**Resultado:** **Roca** (2 votos frente a 1) ✓\n",
    "\n",
    "A continuación se muestra un ejemplo en código de cómo construir un modelo de este tipo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define el **meta-clasificador** a partir de los `base_models`.\n",
    "\n",
    "models[\"Ensemble (Hard Voting)\"] = VotingClassifier(estimators = base_models, voting=:hard)\n",
    "machines[\"Ensemble (Hard Voting)\"] = machine(models[\"Ensemble (Hard Voting)\"], train_input, train_output) |> fit!\n",
    "\n",
    "for (name, machine) in machines\n",
    "    acc = MLJ.accuracy(predict_mode(machine, test_input), test_output)\n",
    "    println(\"$name: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3971c",
   "metadata": {},
   "source": [
    "El problema principal radica en que **confiamos por igual en todos los modelos** a la hora de decidir la clase de respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d50e61",
   "metadata": {},
   "source": [
    "## *Soft Voting* \n",
    "\n",
    "Como se mencionó en la sección anterior, uno de los problemas de los modelos *ensemble* clásicos es que **todos los resultados se ponderan de igual manera** y que, en cada uno de los modelos “débiles”, solo se tiene en cuenta la clase más votada.  \n",
    "\n",
    "Para resolver esta limitación, el *Soft Voting* propone utilizar las **probabilidades** que cada clasificador asigna a cada clase, en lugar de considerar únicamente la clase predicha. El resultado final se obtiene promediando dichas probabilidades y seleccionando la clase con la **mayor probabilidad promedio**.\n",
    "\n",
    "### Ejemplo sin pesos (todos los modelos igualmente importantes)\n",
    "\n",
    "| Clasificador | P(Mina) | P(Roca) |\n",
    "|---------------|---------|---------|\n",
    "| SVM           | 0.9     | 0.1     |\n",
    "| Regresión Logística | 0.3 | 0.7 |\n",
    "| Naive Bayes   | 0.2     | 0.8 |\n",
    "| **Promedio**  | **0.47**| **0.53** |\n",
    "\n",
    "**Cálculo:**\n",
    "- P(Mina) = (0.9 + 0.3 + 0.2) / 3 = 0.47  \n",
    "- P(Roca) = (0.1 + 0.7 + 0.8) / 3 = 0.53  \n",
    "\n",
    "**Resultado:** **Roca** (mayor probabilidad promedio) ✓  \n",
    "\n",
    "**Ventaja frente al _Hard Voting_:**  \n",
    "Aunque el modelo SVM muestra una alta confianza en la clase *Mina* (0.9), los otros dos modelos manifiestan una confianza significativa en *Roca* (0.7 y 0.8). La votación suave permite **capturar y aprovechar esta información de confianza** en la combinación final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b01ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define el **meta-clasificador** a partir de los `base_models`.\n",
    "\n",
    "models[\"Ensemble (Soft Voting - Equal)\"] = VotingClassifier( models = base_models, voting = :soft, weights = nothing) # All models equally weighted\n",
    "machines[\"Ensemble (Soft Voting - Equal)\"] = machine(models[\"Ensemble (Soft Voting - Equal)\"], train_input, train_output) |> fit!\n",
    "for (name, machine) in machines\n",
    "    acc = MLJ.accuracy(predict_mode(machine, test_input), test_output)\n",
    "    println(\"$name: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf78117f",
   "metadata": {},
   "source": [
    "#### *Weighted Soft Voting* (Votación ponderada)\n",
    "\n",
    "Aunque *Soft Voting* mejora el proceso al tener en cuenta el grado de confianza de cada modelo, el principal inconveniente sigue siendo la **igualdad de influencia entre los modelos**.  \n",
    "Para solucionar este aspecto, una de las propuestas consiste en **introducir un sistema de ponderación en la decisión**.  \n",
    "\n",
    "En muchos casos sabemos que algunos modelos presentan un mejor rendimiento que otros.  \n",
    "Por ejemplo, si una **SVM** alcanza una precisión del **85 %**, mientras que los demás modelos rondan el **70 %**, es razonable asignar **mayor peso** a la SVM.  \n",
    "Esto se consigue mediante el uso de **pesos** en la votación suave, donde los valores de probabilidad de cada modelo se **multiplican por su peso** antes de calcular el promedio.  \n",
    "\n",
    "Matemáticamente:\n",
    "\n",
    "$$\n",
    "P(\\text{clase}) = \\frac{\\sum_{i=1}^{n} w_i \\cdot P_i(\\text{clase})}{\\sum_{i=1}^{n} w_i}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "* $w_i$ = peso asignado al modelo $i$  \n",
    "* $P_i(\\text{clase})$ = probabilidad asignada por el modelo $i$ a la clase  \n",
    "* $n$ = número total de modelos  \n",
    "\n",
    "Siguiendo el mismo ejemplo anterior, supongamos que deseamos **incrementar la importancia de la SVM**.\n",
    "\n",
    "### Ejemplo con pesos [2, 1, 1] (peso doble para la SVM)\n",
    "\n",
    "| Clasificador | Peso | P(Mina) | P(Roca) | Contribución Mina | Contribución Roca |\n",
    "|---------------|------|----------|----------|-------------------|-------------------|\n",
    "| SVM           | 2    | 0.9      | 0.1      | 2 × 0.9 = 1.8     | 2 × 0.1 = 0.2     |\n",
    "| Reg. Logística| 1    | 0.3      | 0.7      | 1 × 0.3 = 0.3     | 1 × 0.7 = 0.7     |\n",
    "| Naive Bayes   | 1    | 0.2      | 0.8      | 1 × 0.2 = 0.2     | 1 × 0.8 = 0.8     |\n",
    "| **Suma**      | 4    |          |          | **2.3**           | **1.7**           |\n",
    "| **Promedio ponderado** |  |    |          | **0.575**         | **0.425**         |\n",
    "\n",
    "**Cálculo:**\n",
    "- P(Mina) = (1.8 + 0.3 + 0.2) / 4 = 2.3 / 4 = 0.575  \n",
    "- P(Roca) = (0.2 + 0.7 + 0.8) / 4 = 1.7 / 4 = 0.425  \n",
    "\n",
    "**Resultado:** **Mina** (mayor probabilidad ponderada) ✓\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260da3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"Ensemble (Soft Voting - Weighted)\"] = VotingClassifier(estimators = base_models, voting=:soft,weights=[1,2,2,1])\n",
    "machines[\"Ensembles (Soft Voting - Weighted)\"] = machine(models[\"Ensemble (Soft Voting - Weighted)\"],train_input, train_output) |> fit!\n",
    "\n",
    "for (name, machine) in machines\n",
    "    acc = MLJ.accuracy(predict_mode(machine, test_input), test_output)\n",
    "    println(\"$name: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26ee5d",
   "metadata": {},
   "source": [
    "## Cuándo utilizar cada estrategia\n",
    "\n",
    "### *Hard Voting*\n",
    "\n",
    "- Cuando los modelos solo generan predicciones categóricas (sin probabilidades).  \n",
    "- Cuando todos los modelos tienen una fiabilidad similar.  \n",
    "- Es un método más **simple y rápido**.\n",
    "\n",
    "### *Soft Voting*\n",
    "\n",
    "- Cuando los modelos proporcionan **probabilidades** como salida.  \n",
    "- Cuando todos los modelos presentan **rendimientos comparables**.  \n",
    "- Permite **capturar el grado de confianza** en cada predicción.\n",
    "\n",
    "### *Weighted Soft Voting*\n",
    "\n",
    "- Cuando algunos modelos son claramente **más precisos o robustos** que otros.  \n",
    "- Cuando se desea **asignar mayor importancia** a determinados modelos.  \n",
    "- Los pesos pueden definirse en función de:\n",
    "    - La **precisión de validación**.  \n",
    "    - La **especialización o experiencia** del modelo en un dominio concreto.  \n",
    "    - Métricas relevantes como el **F1-score** u otras medidas de rendimiento.  \n",
    "\n",
    "Para la **selección de los pesos**, pueden emplearse varias estrategias, siendo las más relevantes:\n",
    "\n",
    "1. **Asignación manual**, basada en conocimiento previo del rendimiento de los modelos.  \n",
    "2. **Basada en la precisión de validación**, ajustando los pesos en proporción a los resultados obtenidos.  \n",
    "3. **Optimización mediante búsqueda en _Grid search_**), explorando distintas combinaciones de pesos para maximizar el rendimiento global del *ensemble*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be268b",
   "metadata": {},
   "source": [
    "### Pregunta\n",
    "> ❓Hemos realizado todas las pruebas utilizando una **estrategia *hold-out***; sin embargo, como se indicó en una sesión anterior, se prefiere la aplicación de un enfoque de **validación cruzada (*cross-validation*)** para reducir la dependencia de la selección de las muestras.  \n",
    "\n",
    "En este caso, pueden considerarse dos enfoques diferentes:  \n",
    "\n",
    "1. Aplicar la validación cruzada a cada modelo individualmente, elegir el mejor y combinarlos en un único *ensemble*.  \n",
    "2. Aplicar la validación cruzada al nivel del *ensemble* antes de entrenar los modelos.  \n",
    "\n",
    "¿Cuál de ellos es el correcto y por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fcbb5",
   "metadata": {},
   "source": [
    "`Answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2b304",
   "metadata": {},
   "source": [
    "### *Stacking*\n",
    "\n",
    "Este último enfoque para la combinación de modelos puede considerarse una __variante *Soft Voting*__.   \n",
    "Como se mencionó en dicha sección, la votación suave permite fijar los pesos de cada uno de los modelos, y estos pueden ajustarse mediante una técnica de **gradiente descendente**.  \n",
    "\n",
    "El *Stacking* suele identificarse como una técnica de clasificación superior a una regresión lineal (que es, en esencia, lo que realiza la votación suave), al emplear un **modelo más complejo**, como una **red neuronal artificial (ANN)**, para combinar los resultados de los modelos base.  \n",
    "\n",
    "Así, de manera análoga a lo realizado anteriormente, las salidas de las diferentes técnicas pueden tomarse y utilizarse como **entradas de otro modelo de clasificación**, lo que permite ajustar los pesos y considerar **combinaciones no lineales** de las respuestas de cada modelo.  \n",
    "\n",
    "A continuación se muestra un ejemplo de este proceso en código, utilizando la implementación de `MLJ`, que emplea un **SVC como modelo combinador**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ac43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea una `NamedTuple` con los modelos base.# \n",
    "base_models_NamedTuple = (; (Symbol(name) => model for (name, model) in models)...)\n",
    "\n",
    "# Construir el stacking:\n",
    "# - resampling=CV(...) define cómo se generan las predicciones out-of-fold\n",
    "# - measures=... solo para reporte interno; no afecta al entrenamiento final del stack\n",
    "models[\"Ensemble (Stacking)\"] = Stack(; \n",
    "    metalearner = SVC(),\n",
    "    resampling = CV(nfolds=5, shuffle=true, rng=123),\n",
    "    measures = log_loss,\n",
    "    base_models_NamedTuple...  # Expande la `NamedTuple` de modelos base.\n",
    ")\n",
    "\n",
    "# Entrenar el stack en el train dataset\n",
    "machines[\"Ensemble (Stacking)\"] = machine(stack, train_input, train_output) |> fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed598b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, machine) in machines\n",
    "    acc = MLJ.accuracy(predict_mode(machine, test_input), test_output)\n",
    "    println(\"$name: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9273829",
   "metadata": {},
   "source": [
    "## Creación de modelos\n",
    "\n",
    "Uno de los elementos clave que aún no se ha abordado es la creación de los modelos que compondrán el meta-clasificador. Hasta ahora, el enfoque seguido no es muy adecuado, ya que el conjunto de datos de entrada para todos los modelos es el mismo. Esto provoca una evidente falta de diversidad en los modelos, dado que, sea cual sea el modelo que creemos, dispondrá de la misma información o “punto de vista” que los demás. Sin embargo, esta no es la práctica habitual. En su lugar, el conjunto de patrones de entrada suele **dividirse en subconjuntos más pequeños** con los que entrenar una o varias técnicas, con el doble objetivo de **reducir el coste computacional** por un lado y **aumentar la diversidad de los modelos** por otro. Conviene recordar en este punto que los modelos “débiles” no tienen por qué ser perfectos en todas las clases ni cubrir todas las posibilidades; basta con que sean **rápidos de entrenar** y ofrezcan una salida **razonablemente consistente**.\n",
    "\n",
    "En cuanto a la forma de particionar los datos para la creación de los modelos, la mayoría de los enfoques suelen considerar dos estrategias principales, conocidas como **_Bagging_** y **_Boosting_**. A continuación se describen brevemente ambas.\n",
    "\n",
    "### Bagging o agregación *bootstrap*\n",
    "La técnica conocida como _Bagging_ o selección con reemplazo fue propuesta por **Breitman** en 1996. Se basa en el desarrollo de múltiples modelos que pueden entrenarse en **paralelo**. El elemento clave de estos modelos es que **cada modelo se entrena sobre un subconjunto del conjunto de entrenamiento**. Este subconjunto de datos se extrae **aleatoriamente con reemplazo**. Este último punto es especialmente importante porque, una vez que se ha seleccionado un ejemplo de entre las posibilidades, se **vuelve a colocar** entre las posibilidades para que pueda ser seleccionado nuevamente, ya sea en el subconjunto que se está construyendo o en los subconjuntos de otros modelos; es decir, se crean **conjuntos de ejemplos no disjuntos**.\n",
    "\n",
    "![Bagging Example](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Ensemble_Bagging.svg/440px-Ensemble_Bagging.svg.png)\n",
    "\n",
    "El resultado es la creación de “expertos” en datos **especializados** y dependientes de la partición. Si bien los datos **comunes** o más frecuentes quedan correctamente cubiertos por todos los modelos, también es cierto que los datos **menos frecuentes** tienden a no estar presentes en todas las particiones y pueden no quedar cubiertos en todos los casos. De este modo, se obtienen modelos **más especializados** en ciertos datos o con un **punto de vista distinto**, que se comportan como expertos en una región particular del espacio de búsqueda.\n",
    "\n",
    "Aunque se tratará con mayor detalle más adelante, una técnica bien conocida que emplea este enfoque para la construcción de sus modelos “débiles” es **RandomForest**. En efecto, construye los árboles de decisión que componen el meta-clasificador de esta manera. **Cualquier clasificador** puede utilizarse como base de un _Bagging_ mediante la clase [EnsembleModel](https://juliaai.github.io/MLJ.jl/stable/models/EnsembleModel_MLJEnsembles/#EnsembleModel_MLJEnsembles).\n",
    "\n",
    "Por ejemplo, en el siguiente código se han elegido **10 SVM para clasificación** como modelos débiles. Cada uno de estos modelos se ha entrenado **solo con el 50 %** de los patrones de entrenamiento, por lo que debería **incrementarse la varianza** entre ellos.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7750d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añade un modelo de *Bagging* utilizando **SVC** como modelo base.\n",
    "using MLJEnsembles: EnsembleModel, CPUThreads\n",
    "\n",
    "models[\"Bagging (SVC)\"] = EnsembleModel(\n",
    "    model = SVC(),              # o ProbabilisticSVC()\n",
    "    n = 10,                     # numbero de modelos base \n",
    "    bagging_fraction = 0.50,    # fraction de eejemplos por modelo base\n",
    "    rng = 123,                  \n",
    "    acceleration = CPUThreads() # Utiliza `Threads` para acelerar el entrenamiento, dada la independencia de los modelos base.\n",
    ")\n",
    "\n",
    "machines[\"Bagging (SVC)\"] = machine(models[\"Bagging (SVC)\"], train_input, train_output) |> fit!\n",
    "\n",
    "for (name, machine) in machines\n",
    "    acc = MLJ.accuracy(predict_mode(machine, test_input), test_output)\n",
    "    println(\"$name: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5787a56",
   "metadata": {},
   "source": [
    "Como alternativa a la extracción de ejemplos completos, podría realizarse una **partición vertical** del conjunto de entrenamiento, extrayendo así **características** (*features*).  \n",
    "Para implementar esta alternativa, en la función `EnsembleModel` debe definirse el parámetro **`bagging_fraction`**.  \n",
    "\n",
    "Este enfoque se utiliza especialmente cuando el número de características es muy elevado, con el objetivo de crear **modelos más simples** que no utilicen toda la información disponible, ya que esta suele contener redundancia.  \n",
    "\n",
    "Es importante destacar que este procedimiento de extracción de características para los modelos se realiza **sin reemplazo**, es decir, las características seleccionadas para un clasificador **no se vuelven a incluir** en la lista de posibilidades hasta que se construye el conjunto correspondiente al siguiente clasificador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0484f377",
   "metadata": {},
   "source": [
    "### *Boosting*\n",
    "\n",
    "La otra gran familia de técnicas para el meta-modelado *ensemble* es la conocida como **_Boosting_**.En este caso, el enfoque es ligeramente diferente, ya que el objetivo es crear una **cadena de clasificadores**.La idea clave es que cada clasificador sucesivo se vuelve **más especializado en los patrones que los modelos anteriores clasificaron incorrectamente**.  \n",
    "\n",
    "Así, al igual que en el caso anterior, se selecciona un subconjunto de patrones del conjunto original, pero este proceso se realiza **de manera secuencial y sin reemplazo**.Esto provoca que los nuevos aprendices se centren progresivamente en los casos más difíciles, generando gradualmente un modelo compuesto más robusto y preciso.  \n",
    "\n",
    "Por tanto, como en el *Bagging*, la idea subyacente de este enfoque es que **no todos los modelos deben utilizar todos los patrones como base**, pero, a diferencia del *Bagging*, este proceso es **lineal**, debido a la **dependencia entre la construcción de los modelos**. Finalmente, las salidas de los modelos individuales se combinan mediante una **votación mayoritaria ponderada**, donde el peso de cada clasificador refleja su rendimiento durante el entrenamiento.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Ensemble_Boosting.svg/1920px-Ensemble_Boosting.svg.png\" alt=\"Boosting examples\" width=\"600\"/>\n",
    "\n",
    "#### AdaBoost\n",
    "\n",
    "El algoritmo **AdaBoost** comienza asignando **pesos iguales** a todas las instancias del conjunto de entrenamiento. A continuación, se entrena un clasificador sencillo (denominado *stump*, que consiste en un árbol de decisión de un solo nivel) y se evalúa su rendimiento. Las instancias mal clasificadas reciben **mayor peso**, de modo que el siguiente clasificador se centra más en esos casos difíciles.  \n",
    "\n",
    "Este proceso iterativo continúa, actualizando los pesos en cada iteración y creando un nuevo modelo débil que complementa a los anteriores. En **AdaBoost**, la ponderación tanto de las instancias como de los clasificadores se basa en una **función de pérdida exponencial**, que penaliza las clasificaciones erróneas de manera exponencial. La predicción final del *ensemble* se obtiene mediante una **votación mayoritaria ponderada** entre todos los clasificadores débiles.  \n",
    "\n",
    "En **MLJ**, este comportamiento está implementado mediante el modelo `AdaBoostStumpClassifier`, proporcionado por el paquete `DecisionTree.jl`.\n",
    "\n",
    "#### Gradient Boosting\n",
    "\n",
    "El **Gradient Boosting** sigue un principio distinto: en lugar de reajustar los pesos de las instancias de forma explícita, utiliza un enfoque de **descenso por gradiente** para minimizar una función de pérdida. Cada nuevo árbol de la secuencia se entrena para predecir los **errores residuales** (o gradientes) del *ensemble* anterior, refinando gradualmente el modelo.  \n",
    "\n",
    "En el caso de la clasificación, cada árbol de decisión modela la **verosimilitud logística** de los datos, y sus predicciones se combinan para estimar las probabilidades de clase. La decisión final se obtiene a partir de la **suma de estas probabilidades** a lo largo de todos los árboles.  \n",
    "\n",
    "En **MLJ**, este procedimiento puede implementarse mediante el modelo `EvoTreeClassifier` (del paquete `EvoTrees.jl`), que es conceptualmente similar al `GradientBoostingClassifier` de *scikit-learn*, aunque está escrito íntegramente en Julia y admite **aceleración tanto por CPU como por GPU**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "using MLJBase: accuracy\n",
    "\n",
    "# Carga modelos (puro Julia)\n",
    "AdaBoostStumpClassifier = @load AdaBoostStumpClassifier pkg=DecisionTree\n",
    "EvoTreeClassifier = @load EvoTreeClassifier pkg=EvoTrees\n",
    "\n",
    "# AdaBoost (similar a sklearn AdaBoostClassifier con stumps)\n",
    "models[\"AdaBoost\"] = AdaBoostStumpClassifier(n_iter = 30)\n",
    "machines[\"AdaBoost\"] = machine(models[\"AdaBoost\"], train_input, train_output) |> fit!(\n",
    "\n",
    "\n",
    "# Gradient Boosting (similar a sklearn GradientBoostingClassifier)\n",
    "models[\"EvoTrees\"] = EvoTreeClassifier(\n",
    "    nrounds=30,\n",
    "    eta=1.0,\n",
    "    max_depth=2,\n",
    "    loss=:logistic\n",
    ")\n",
    "\n",
    "machines[\"EvoTrees\"] = machine(models[\"EvoTrees\"], train_input, train_output) |> fit!()\n",
    "\n",
    "\n",
    "for (name, machine) in machines\n",
    "    acc = MLJ.accuracy(predict_mode(machine, test_input), test_output)\n",
    "    println(\"$name: $(acc*100) %\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43fc04b",
   "metadata": {},
   "source": [
    "### Pregunta\n",
    "> De forma análoga a la sección de validación cruzada, desarrolla una función para entrenar *ensembles*.  \n",
    "La función, denominada `trainClassEmsemble`, seguirá también una **validación cruzada estratificada**.  \n",
    "A modo de recordatorio rápido, los pasos que debe cubrir la función son:\n",
    "\n",
    "1. **Crear un vector con *k* elementos**, que contendrá los resultados en test del proceso de validación cruzada con la métrica seleccionada.  \n",
    "\n",
    "2. **Realizar un bucle de *k* iteraciones** (*k* *folds*) en el que, dentro de cada iteración y a partir de las matrices de entradas y salidas deseadas, mediante el vector de índices resultante de la función previa, se creen **4 matrices**: entradas y salidas deseadas para **entrenamiento** y para **prueba**. \n",
    "\n",
    "3. **Dentro de este bucle**, añadir una llamada para **generar los modelos**, que pueden ser cualquiera de los utilizados en la **Unidad 6**. \n",
    "\n",
    "4. **Entrenar esos modelos** utilizando el conjunto de entrenamiento correspondiente, es decir, los **K subconjuntos restantes** no usados para prueba.\n",
    "\n",
    "5. En caso de necesitar un **conjunto de validación** (p. ej., para *early stopping* u otros fines), **dividir el conjunto de entrenamiento en dos partes**. Para ello, utiliza la función `holdOut`. \n",
    "\n",
    "4. **Construir el *ensemble*** siguiendo una de las estrategias descritas anteriormente (cualquiera de ellas) y **calcular el rendimiento en test**.  \n",
    "\n",
    "6. Finalmente, **proporcionar el resultado del promedio** de los valores de estos vectores para cada métrica **junto con sus desviaciones estándar**. \n",
    "\n",
    "Como resultado de esta llamada, al menos debería devolverse **el valor en test en la(s) métrica(s) seleccionada(s)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55290ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "function trainClassEnsemble(estimators::AbstractArray{Symbol,1}, \n",
    "        modelsHyperParameters:: AbstractArray{Dict, 1},     \n",
    "        trainingDataset::Tuple{AbstractArray{<:Real,2}, AbstractArray{Bool,2}},    \n",
    "        kFoldIndices::     Array{Int64,1})\n",
    "    #TODO\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265be0c",
   "metadata": {},
   "source": [
    "### Pregunta\n",
    "> ❓ Repite la función anterior, pero esta vez permitiendo **un único estimador** como base. Este puede **replicarse** y pasarse a la función previa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "function trainClassEnsemble(baseEstimator::Symbol, \n",
    "        modelsHyperParameters::Dict,\n",
    "        NumEstimators::Int=100,\n",
    "        trainingDataset::Tuple{AbstractArray{<:Real,2}, AbstractArray{Bool,2}},     \n",
    "        kFoldIndices::     Array{Int64,1})\n",
    "    #TODO\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154068c",
   "metadata": {},
   "source": [
    "## Técnicas que integran el enfoque *Ensemble*\n",
    "\n",
    "Algunos de los algoritmos más conocidos y actualmente utilizados se basan en este tipo de enfoque. Entre ellos, quizás los más representativos y ampliamente empleados son aquellos basados en la **generación de Árboles de Decisión simples (DT)**. La razón de su uso radica en su **fácil interpretación**, así como en su **rapidez de cálculo y entrenamiento**. A continuación, se presentan los dos enfoques más conocidos en este sentido: ***Random Forest*** y ***XGBoost***.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "El algoritmo **Random Forest**, propuesto por **Breiman y Cutler** en 2006 (a partir de una idea previa de **Ho** en 1995, conocida como *Random Subspaces*), constituye uno de los ejemplos más representativos del aprendizaje mediante *ensembles*. Combina múltiples clasificadores simples —en este caso, **Árboles de Decisión (DTs)**— en un modelo único y más robusto. Cada árbol del bosque se entrena sobre una **muestra *bootstrap*** (un subconjunto aleatorio con reemplazo) del conjunto de datos original, siguiendo un enfoque de *bagging*. Dado que cada árbol se entrena de manera independiente, el proceso puede ser completamente **paralelizado**.  \n",
    "\n",
    "En problemas de **clasificación**, la predicción final se obtiene mediante una **votación mayoritaria** entre todos los árboles; en **regresión**, mediante el **promedio** de sus salidas.\n",
    "\n",
    "Los **Random Forests** destacan por ofrecer un rendimiento notable con **mínimo ajuste de hiperparámetros**. Normalmente, el parámetro más importante es el **número de árboles** (`n_trees` en MLJ o `n_estimators` en *scikit-learn*), que controla el tamaño del *ensemble*. Una heurística común sugiere utilizar:\n",
    "\n",
    "- *$\\sqrt{\\textrm{\\#features}}$* para tareas de clasificación  \n",
    "- *$\\frac{\\textrm{\\#features}}{3}$* para tareas de regresión  \n",
    "\n",
    "Aunque aumentar el número de árboles suele mejorar el rendimiento, este incremento tiende a **saturarse** más allá de los **500–1000 árboles** en la mayoría de los casos prácticos.\n",
    "\n",
    "Además del proceso de *bootstrapping*, los Random Forest introducen un **segundo nivel de aleatoriedad**: en cada división de nodo, solo se considera un **subconjunto aleatorio de características** como candidatas para la partición. Esto incrementa la **diversidad entre los árboles** y contribuye a **reducir la varianza del modelo**, manteniendo al mismo tiempo una alta capacidad predictiva.  \n",
    "\n",
    "Un subproducto relevante de este mecanismo es la posibilidad de **cuantificar la importancia de las características**. Analizando cuánto contribuye cada variable a la reducción de la impureza de los nodos a lo largo de todos los árboles, los Random Forest pueden estimar la **importancia relativa de cada característica**. Esta importancia basada en la impureza se emplea frecuentemente para **selección de características**.  \n",
    "La métrica de impureza más común es el **índice de Gini**, definido como:\n",
    "\n",
    "$$\n",
    "G = \\sum_{i=1}^C p(i) \\cdot (1 - p(i))\n",
    "$$\n",
    "\n",
    "donde $C$ es el número de clases y $p(i)$ es la probabilidad de seleccionar aleatoriamente una instancia de la clase $i$. Intuitivamente, mide la probabilidad de clasificar incorrectamente una instancia elegida al azar si las etiquetas se asignaran de acuerdo con la distribución de clases. Para una explicación visual excelente, véase [esta referencia](https://victorzhou.com/blog/gini-impurity/).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668be4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "using MLJBase: accuracy\n",
    "using Plots\n",
    "\n",
    "# Cargar el modelo Random Forest nativo de Julia\n",
    "RandomForestClassifier = @load RandomForestClassifier pkg=DecisionTree\n",
    "\n",
    "# Definir el modelo\n",
    "models[\"RF\"] = RandomForestClassifier(\n",
    "    n_trees=8,              \n",
    "    max_depth=-1,           \n",
    "    min_samples_split=2,\n",
    "    n_subfeatures=-1,       \n",
    "    sampling_fraction=1.0   \n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "machines[\"RF\"] = machine(models[\"RF\"], train_input, train_output) |> fit!\n",
    "\n",
    "    \n",
    "# Evaluar los modelos e imprimir el accuracy\n",
    "for (name, mach) in machines\n",
    "    acc = accuracy(predict_mode(mach, test_input), test_output)\n",
    "    println(\"$name: $(round(acc*100, digits=2)) %\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbe372",
   "metadata": {},
   "source": [
    "### Hiperparámetros clave\n",
    "\n",
    "| **Parámetro**         | **Descripción** |\n",
    "|------------------------|-----------------|\n",
    "| `n_trees`              | Número de árboles en el bosque (equivalente a `n_estimators` en *scikit-learn*). |\n",
    "| `max_depth`            | Profundidad máxima de cada árbol. Usar `-1` para no establecer límite. |\n",
    "| `min_samples_split`    | Número mínimo de muestras requeridas para dividir un nodo. |\n",
    "| `n_subfeatures`        | Número de características aleatorias consideradas en cada división (`-1` utiliza √(#features)). |\n",
    "| `sampling_fraction`    | Fracción de muestras de entrenamiento empleadas para construir cada árbol (*bootstrapping*). |\n",
    "| `rng`                  | Generador de números aleatorios para garantizar la reproducibilidad. |\n",
    "\n",
    "En este ejemplo, el número de árboles (`n_trees`) se define siguiendo la heurística de $\\sqrt{\\textrm{\\#features}}$. Dado que el conjunto de datos utilizado en este ejemplo es relativamente pequeño, los resultados pueden **variar ligeramente entre ejecuciones**, dependiendo de las particiones aleatorias utilizadas durante el entrenamiento.\n",
    "\n",
    "#### Importancia de características\n",
    "\n",
    "Una vez entrenado el modelo, puede calcularse la **importancia de las características** a partir de la **reducción media de la impureza de Gini** en todos los árboles del bosque.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer los parámetros de los modelos ajustados\n",
    "fitted_model = fitted_params(machines[\"RF\"])\n",
    "\n",
    "# Obtner la importancia de las características\n",
    "feature_importances = fitted_model.features_importance\n",
    "\n",
    "# Imprimir la importancia de las características\n",
    "p = bar(\n",
    "    1:length(feature_importances),\n",
    "    feature_importances,\n",
    "    orientation = :horizontal,\n",
    "    legend = false\n",
    ")\n",
    "xlabel!(p, \"Gini Gain\")\n",
    "ylabel!(p, \"Feature\")\n",
    "title!(p, \"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4feb1ec",
   "metadata": {},
   "source": [
    "Como se muestra en la gráfica, gran parte de la información predictiva puede concentrarse en un **número reducido de características**.  \n",
    "Por tanto, esta métrica también puede emplearse para la **filtración o selección de características**, aspecto que se abordará en secciones posteriores.\n",
    "\n",
    "Los **Random Forests** representan uno de los métodos *ensemble* más **robustos y ampliamente utilizados**.  \n",
    "Aprovechan el *bagging* y la **aleatoriedad en la selección de características** para construir árboles diversos, reduciendo la varianza y mejorando la capacidad de generalización.  \n",
    "Además, proporcionan de forma natural medidas interpretables, como la **importancia de las características**, lo que los convierte no solo en **predictores potentes**, sino también en **herramientas útiles para el análisis exploratorio de datos**.\n",
    "\n",
    "---\n",
    "\n",
    "### XGBoost (*eXtreme Gradient Boosting*)\n",
    "\n",
    "Por último, en esta sección final, debe mencionarse nuevamente el **Gradient Boosting**, en concreto una implementación que en los últimos años se ha hecho muy conocida por su **versatilidad y velocidad**. Esta implementación es conocida como ***XGBoost (eXtreme Gradient Boosting)***, y ha destacado especialmente en competiciones de plataformas como **Kaggle**, debido a su **rapidez de ejecución** y **robustez en los resultados**.  \n",
    "\n",
    "El ***XGBoost*** constituye un *ensemble* similar al **Random Forest**, pero utiliza un clasificador base diferente denominado **CART** (*Classification and Regression Trees*), en lugar de los simples *Decision Trees*.  \n",
    "Este cambio responde a la necesidad del algoritmo de obtener **probabilidades asociadas a las decisiones**, como sucede en el *Gradient Tree Boosting*. La otra diferencia fundamental de este algoritmo, al basarse en *Gradient Tree Boosting*, es el **cambio de la estrategia de *bagging* a *boosting*** para la creación de los conjuntos de entrenamiento de los clasificadores.\n",
    "\n",
    "Posteriormente, esta técnica lleva a cabo un **entrenamiento aditivo**, cuyos pesos se ajustan mediante un **descenso por gradiente** sobre una función de pérdida (*loss function*) previamente definida. Al añadir un término de **regularización** a dicha función de pérdida, puede calcularse la **segunda derivada** de las funciones, lo que permite actualizar los pesos de clasificación de los distintos árboles. El cálculo de este gradiente posibilita ajustar los valores de los clasificadores generados posteriormente, de modo que los pesos concentren la atención en los **patrones clasificados de forma incorrecta**. Los detalles matemáticos de la implementación pueden consultarse en este [enlace](https://xgboost.readthedocs.io/en/stable/tutorials/model.html).\n",
    "\n",
    "A diferencia de los otros enfoques vistos, **`xgboost` no está actualmente implementado dentro de `scikit-learn`** pero si en **MLJ**. Aun así en este caso **instalar la versión de referencia** si aún no se encuentra disponible en el sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03972c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e0c0f",
   "metadata": {},
   "source": [
    " Tras la instalación, la biblioteca puede utilizarse como se muestra en el siguiente ejemplo. A diferencia de otras implementaciones, la versión en **Julia** admite como entrada los formatos **Julia Array**, **SparseMatrixCSC**, **texto en formato libSVM** y **archivo binario de XGBoost**.  \n",
    "\n",
    "Aunque las amplias opciones ofrecidas por la biblioteca de Julia permiten realizar conversiones internas al formato [LIBSVM](https://xgboost.readthedocs.io/en/stable/tutorials/input_format.html), como ocurre con otras bibliotecas, esta implementación **no soporta todas las posibilidades**. En particular, el tipo **`BitVector`** **no es actualmente compatible** con la función `DMatrix`. Por tanto, es necesario realizar un **pequeño cambio en el formato de los datos** antes de utilizar la biblioteca.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using XGBoost;\n",
    "\n",
    "train_input = input_data\n",
    "train_output = output_data\n",
    "\n",
    "test_input = input_data\n",
    "test_output = output_data\n",
    "\n",
    "train_output_asNumber= Vector{Number}(train_output);\n",
    "\n",
    "@assert train_output_asNumber isa Vector{Number}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad57fb4",
   "metadata": {},
   "source": [
    "Una vez realizada esta adaptación de los datos, se puede proceder al **entrenamiento de un modelo** utilizando la biblioteca `xgboost`.  \n",
    "Para ello, basta con llamar a la función `train` con los parámetros correspondientes.  \n",
    "Entre estos parámetros, los más relevantes son:\n",
    "\n",
    "- **eta**: término que determina la **tasa de aprendizaje** o compresión de los pesos después de cada nueva etapa de *boosting*.  \n",
    "  Toma valores entre 0 y 1.  \n",
    "- **max_depth**: profundidad máxima de los árboles.  \n",
    "  Su valor por defecto es 6; incrementarlo permite construir modelos más complejos.  \n",
    "- **gamma**: parámetro que controla la **reducción mínima de la función de pérdida** necesaria para realizar una nueva partición en una hoja del árbol.  \n",
    "  Cuanto mayor sea su valor, más **conservador** será el modelo.  \n",
    "- **alpha** y **lambda**: parámetros que controlan la **regularización L1 y L2**, respectivamente.  \n",
    "- **objective**: define la **función de pérdida** a utilizar, que puede ser una de las predefinidas en la biblioteca.  \n",
    "  La lista completa de opciones puede consultarse en este [enlace](https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster).\n",
    "\n",
    "Además, solo es necesario establecer el **número máximo de iteraciones** del proceso de *boosting*, como se muestra en el siguiente ejemplo, con **20 rondas** de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec905d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_data = DMatrix(train_input, label=train_output_asNumber)\n",
    "\n",
    "model = xgboost(svm_data, rounds=20, eta = 1, max_depth = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275ed94",
   "metadata": {},
   "source": [
    "En el siguiente fragmento de código, varios parámetros se pasan en forma de **diccionario**, y se calculan **dos métricas diferentes**.  La primera, *error*, se refiere al número de instancias clasificadas incorrectamente sobre el total; la segunda es el **Área Bajo la Curva ROC (AUC)**.\n",
    "\n",
    "### Pregunta\n",
    "> ❓ ¿Cuál es el nombre canónico de la primera medida que se está monitorizando?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [\"max_depth\" => 2,\n",
    "         \"eta\" => 1,\n",
    "         \"objective\" => \"binary:logistic\"]\n",
    "metrics = metrics = [\"error\", \"auc\"]\n",
    "model = xgboost(DMatrix(train_input, label=train_output_asNumber), rounds=20, param=param, metrics=metrics)\n",
    "\n",
    "pred = predict(model, train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120deba",
   "metadata": {},
   "source": [
    "***Importante***\n",
    "\n",
    "En caso de utilizar un **conjunto de validación**, este debe pasarse mediante el parámetro **`evals`** de la función de entrenamiento.  \n",
    "Además, **solo cuando dicho parámetro `evals` está definido**, es posible establecer las **rondas de parada temprana** mediante el parámetro **`early_stopping_rounds`** de la función `train`.  \n",
    "\n",
    "El código sería similar al siguiente:\n",
    "\n",
    "```julia\n",
    "evals = DMatrix(val_input, label=val_output)\n",
    "xgb_model = xgb.train(param, train_input, num_round, label=train_output_asNumber, \n",
    "                      evals=evals, early_stopping_rounds=10)\n",
    "```\n",
    "El valor proporcionado en la salida corresponde a la **suma de las salidas de los árboles**, situándose **entre 0 y 1** para representar la **probabilidad de pertenencia a una clase dada**. Dado que se trata de un problema de clasificación binaria, basta con establecer un umbral de 0.5 sobre la salida para determinar la clase predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468354c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using XGBoost: predict as predict_xgb\n",
    "\n",
    "pred = predict_xgb(model, test_input)\n",
    "print(\"Error of XGboost= \", sum((pred .> 0.5) .!= test_output) / float(size(pred)[1]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d26f2",
   "metadata": {},
   "source": [
    "Finalmente, al igual que en el caso de **Random Forest**, es posible **identificar la importancia de las características** y representarla gráficamente según su posición en el **ranking de relevancia**. Con el siguiente fragmento de código puede visualizarse dicho indicador, **ordenado de forma ascendente**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e86f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_gain =  [(first(x),last(x)) for x in importance(model)]\n",
    "feature, gain = first.(feature_gain), last.(feature_gain)\n",
    "\n",
    "using Plots;\n",
    "\n",
    "p = bar(feature, y=gain, orientation=\"h\", legend=false)\n",
    "xlabel!(p,\"Gain\")\n",
    "ylabel!(p,\"Feature\")\n",
    "title!(\"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533db36",
   "metadata": {},
   "source": [
    "Como puede observarse, **no todas las características tienen la misma importancia**.  \n",
    "Debe tenerse en cuenta que el eje *Feature* identifica la **posición en el vector de características**, el cual se ordena **por defecto según el valor de ganancia (*gain*)**.\n",
    "\n",
    "## Técnicas más modernas\n",
    "\n",
    "En los últimos años han surgido nuevas implementaciones de algoritmos basados en *ensemble learning* que buscan **optimizar el rendimiento y la eficiencia computacional** de los métodos clásicos de *Gradient Boosting*.  \n",
    "Entre estas destacan **LightGBM** y **CatBoost**, dos librerías de alto rendimiento ampliamente utilizadas tanto en la investigación como en la práctica profesional.\n",
    "\n",
    "Ambos algoritmos parten de la misma base teórica del *Gradient Boosting*, pero introducen **mejoras sustanciales en velocidad, manejo de datos categóricos y escalabilidad**.  \n",
    "Estas optimizaciones los convierten en herramientas especialmente adecuadas para conjuntos de datos **grandes, complejos o heterogéneos**.  \n",
    "\n",
    "En las siguientes secciones se presentan brevemente las características principales de **LightGBM** y **CatBoost**, junto con ejemplos prácticos de su uso e integración dentro del ecosistema **MLJ** de Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87111d0",
   "metadata": {},
   "source": [
    "#### LightGBM\n",
    "\n",
    "**LightGBM (Light Gradient Boosting Machine)** es una implementación moderna y altamente optimizada del algoritmo de *Gradient Boosting*, desarrollada por **Microsoft Research**.  \n",
    "Está diseñada específicamente para ofrecer **gran velocidad y eficiencia** en contextos con **grandes volúmenes de datos** y **alto número de características**, resolviendo algunos de los problemas de escalabilidad presentes en **XGBoost**.\n",
    "\n",
    "A diferencia de otros algoritmos de *boosting*, LightGBM introduce dos innovaciones fundamentales:\n",
    "\n",
    "1. **Crecimiento de los árboles orientado a hojas (Leaf-wise growth)**:  \n",
    "   En lugar de crecer los árboles nivel por nivel (*level-wise*), como hace XGBoost, LightGBM expande las ramas que más reducen la pérdida (*loss*).  \n",
    "   Esto produce modelos más precisos, aunque con mayor riesgo de sobreajuste si no se controla la profundidad.\n",
    "\n",
    "2. **Histogram-based Decision Tree Learning**:  \n",
    "   Los valores continuos se agrupan en histogramas, reduciendo el uso de memoria y acelerando el cálculo de los puntos de división óptimos.\n",
    "\n",
    "#### Instalación\n",
    "Para su uso en Julia, la librería se ejecuta sobre su backend en Python, por lo que puede ser más lenta en entornos no nativos.  \n",
    "Se instala con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"LightGBM\")\n",
    "A partir de ese punto se procederá al uso y configuración de los parámetros de la librería \n",
    "using LightGBM;\n",
    "\n",
    "train_input = input_data\n",
    "train_output = output_data\n",
    "\n",
    "test_input = input_data\n",
    "test_output = output_data\n",
    "\n",
    "model = LGBMClassification(\n",
    "    objective = \"binary\",\n",
    "    num_iterations = 100,\n",
    "    learning_rate = .1,\n",
    "    early_stopping_round = 5,\n",
    "    feature_fraction = .8,\n",
    "    bagging_fraction = .9,\n",
    "    bagging_freq = 1,\n",
    "    num_leaves = 1000,\n",
    "    num_class = 1,\n",
    "    metric = [\"auc\", \"binary_logloss\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8908b76",
   "metadata": {},
   "source": [
    "\n",
    "Como se pude ver, los parámetros más importantes son:\n",
    "\n",
    "* **objective: \"binary\"**. Define la función objetivo que el modelo intentará optimizar. En este caso, \"binary\" indica que es un problema de clasificación binaria.\n",
    "* **num_iterations: 100.**  El número total de iteraciones (o árboles) que se construirán durante el entrenamiento. Un número mayor puede mejorar la precisión, pero también puede llevar a un sobreajuste.\n",
    "* **learning_rate: .1**. La tasa de aprendizaje, también conocida como \"eta\". Controla cuánto ajusta el modelo los pesos en cada iteración. Un valor menor puede hacer que el modelo aprenda más lentamente pero de manera más precisa.\n",
    "* **early_stopping_round: 5**. Si se usa un conjunto de validación, el entrenamiento se detendrá si no hay mejora en la métrica de evaluación durante early_stopping_round iteraciones consecutivas. Esto ayuda a evitar el sobreajuste.\n",
    "* **feature_fraction: .8**. El porcentaje de características (features) que se usan en cada iteración para construir un árbol. Reducir este valor puede ayudar a evitar el sobreajuste y acelerar el entrenamiento.\n",
    "* **bagging_fraction: .9**. El porcentaje de datos que se utilizan en cada iteración para construir los árboles. Es una forma de realizar \"bagging\" y también ayuda a evitar el sobreajuste.\n",
    "* **bagging_freq: 1**. La frecuencia con la que se realiza el bagging. Si se establece en 1, el bagging se realiza en cada iteración. Si se establece en un valor mayor, el bagging se realiza cada bagging_freq iteraciones.\n",
    "* **num_leaves: 1000**. El número máximo de hojas en un árbol. Aumentar este valor puede permitir que el modelo capture más complejidad, pero también puede llevar a un sobreajuste.\n",
    "* **num_class: 1**. El número de clases en el problema de clasificación. Para clasificación binaria, se establece en 1. Para clasificación multiclase, se establece en el número de clases.\n",
    "* **metric: [\"auc\", \"binary_logloss\"]**. La lista de métricas que se utilizarán para evaluar el rendimiento del modelo. \"auc\" es el Área Bajo la Curva ROC, y \"binary_logloss\" es la pérdida logarítmica binaria, que mide la calidad de las predicciones.\n",
    "\n",
    "Lo único que queda es entrenar y usar el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b379680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the estimator on the training data and return its scores for the test data.\n",
    "fit!(model, train_input, train_output, (test_input, test_output))\n",
    "\n",
    "# Predict arbitrary data with the estimator.\n",
    "predict(model, test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c1a92",
   "metadata": {},
   "source": [
    "#### Integración con MLJ\n",
    "\n",
    "LightGBM está disponible en el ecosistema de MLJ a través del paquete MLJLightGBMInterface.jl\n",
    ".\n",
    "Esto permite entrenar, evaluar y ajustar modelos de LightGBM siguiendo la misma estructura de machine() y fit!() utilizada en MLJ:\n",
    "\n",
    "```julia\n",
    "using MLJ, MLJLightGBMInterface\n",
    "\n",
    "model = @load LightGBMClassifier pkg=MLJLightGBMInterface\n",
    "clf = model(num_iterations=100, learning_rate=0.1, max_depth=-1)\n",
    "mach = machine(clf, X, y)\n",
    "fit!(mach)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24efdba6",
   "metadata": {},
   "source": [
    "LightGBM incluye funciones para búsqueda de hiperparámetros (`cv`, `search_cv`) y ofrece soporte tanto para CPU como GPU.\n",
    "Además, los modelos pueden guardarse y cargarse fácilmente:\n",
    "\n",
    "```julia\n",
    "# Save and load the fitted model.\n",
    "filename = pwd() * \"/lightGBM.model\"\n",
    "savemodel(model, filename)\n",
    "loadmodel!(model, filename)\n",
    "\n",
    "```\n",
    "\n",
    "### CatBoost\n",
    "\n",
    "**CatBoost (Categorical Boosting)** es un algoritmo de *Gradient Boosting* desarrollado por **Yandex**, diseñado específicamente para tratar de forma eficiente **variables categóricas** sin necesidad de un preprocesamiento intensivo.  \n",
    "Su principal fortaleza radica en que **codifica internamente las variables categóricas** mediante combinaciones estadísticas y ordenamientos aleatorios, evitando el uso de *one-hot encoding* y reduciendo el riesgo de sobreajuste.\n",
    "\n",
    "CatBoost también introduce innovaciones que mejoran la estabilidad del modelo:\n",
    "\n",
    "1. **Orden aleatorio controlado (*ordered boosting*)**:  \n",
    "   Se evita la dependencia de la muestra durante el cálculo del gradiente, reduciendo el *prediction shift*.\n",
    "\n",
    "2. **Combinación eficiente de características categóricas**:  \n",
    "   Genera automáticamente nuevas variables basadas en combinaciones de categorías, mejorando la capacidad predictiva sin intervención manual.\n",
    "\n",
    "#### Instalación\n",
    "CatBoost se ejecuta también sobre su versión en Python y puede instalarse mediante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de98bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"CatBoost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f48bf41",
   "metadata": {},
   "source": [
    "Desde ese punto se puede hacer un uso similar al de LighGBM o XGboost, soportando varios formatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CatBoost;\n",
    "using PythonCall;\n",
    "\n",
    "train_input = input_data\n",
    "train_output = output_data\n",
    "\n",
    "test_input = input_data\n",
    "test_output = output_data\n",
    "\n",
    "model = CatBoostclassifier(iterations = 2, learning_rate = 1, depth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50281296",
   "metadata": {},
   "source": [
    "Una vez definido el modelo este puede entrenarse y usarse como sigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit model\n",
    "fit!(model, train_data, train_labels)\n",
    "\n",
    "# Get predictions\n",
    "preds = predict(model, eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c56a860",
   "metadata": {},
   "source": [
    "Principales parámetros\n",
    "\n",
    "* iterations: número de iteraciones o árboles (por defecto 1000).\n",
    "\n",
    "* learning_rate: tasa de aprendizaje, típicamente entre 0.01 y 0.1.\n",
    "\n",
    "* depth: profundidad máxima de los árboles.\n",
    "\n",
    "* l2_leaf_reg: regularización L2.\n",
    "\n",
    "* eval_metric: métrica de evaluación (por ejemplo, AUC, Accuracy).\n",
    "\n",
    "* early_stopping_rounds: número de iteraciones sin mejora antes de detener el entrenamiento.\n",
    "\n",
    "* bootstrap_type: método de bootstrap (Bayesian, Bernoulli, Poisson, etc.).\n",
    "\n",
    "* task_type: define si se entrena en CPU o GPU.\n",
    "\n",
    "Integración con MLJ\n",
    "\n",
    "CatBoost también se encuentra disponible en MLJ mediante el paquete MLJCatBoostInterface.jl\n",
    ".\n",
    "Esto permite utilizarlo en flujos MLJ de forma homogénea:\n",
    "``` julia\n",
    "using MLJ, MLJCatBoostInterface\n",
    "\n",
    "model = @load CatBoostClassifier pkg=MLJCatBoostInterface\n",
    "clf = model(iterations=500, learning_rate=0.05, depth=8)\n",
    "mach = machine(clf, X, y)\n",
    "fit!(mach)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a716877",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Notas sobre Julia\n",
    "\n",
    "### Comprendiendo `coerce` en MLJ\n",
    "\n",
    "Al trabajar con conjuntos de datos en **MLJ**, es importante entender que el sistema distingue entre los **tipos de máquina** (por ejemplo, `Int64`, `Float64`, `String`) y los **tipos científicos** (*scientific types* o *scitypes*), que describen cómo deben **interpretarse los datos** en el contexto del modelado.\n",
    "\n",
    "### Por qué se necesita `coerce`\n",
    "\n",
    "Los modelos de **MLJ** no se basan en los tipos nativos de Julia, sino que esperan que las variables tengan **significados científicos** explícitos:\n",
    "- Una columna numérica puede representar una característica **continua**.  \n",
    "- Una columna de texto (*string*) puede representar una característica **categórica**.  \n",
    "- Una columna booleana o entera puede ser **ordenada** o **no ordenada**, según el contexto.\n",
    "\n",
    "Dado que Julia no puede inferir esto automáticamente, utilizamos la función `coerce()` para **indicar explícitamente a MLJ cómo debe interpretar cada columna**.  \n",
    "De este modo, se garantiza la **compatibilidad entre los datos y el modelo de MLJ** que se desea emplear.\n",
    "\n",
    "---\n",
    "\n",
    "### Ejemplo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ, DataFrames, CSV\n",
    "\n",
    "# Carrgar el conjunto de datos Sonar\n",
    "data = CSV.read(\"sonar.csv\", DataFrame)\n",
    "\n",
    "# Inspeccionar los tipos de columna actuales\n",
    "schema(data)\n",
    "\n",
    "# Supongamos que la última columna es el objetivo ('Rock' o 'Mine')\n",
    "y, X = unpack(data, ==(:Target), rng=123)\n",
    "\n",
    "# Convertir la variable objetivo a categórica\n",
    "y = coerce(y, Multiclass)\n",
    "\n",
    "# Convertir todas las columnas de características a continuas\n",
    "X = coerce(X, autotype(X, rules = (:discrete_to_continuous,)))\n",
    "\n",
    "# Verificar los nuevos tipos\n",
    "schema(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39a8f6",
   "metadata": {},
   "source": [
    "### Ejemplos comunes\n",
    "\n",
    "| Situación                             | Qué hacer                | Ejemplo                               |\n",
    "| ------------------------------------- | ------------------------ | ------------------------------------- |\n",
    "| Etiquetas categóricas almacenadas como cadenas | Convertir a `Multiclass` | `y = coerce(y, Multiclass)`           |\n",
    "| Características numéricas             | Convertir a `Continuous` | `X = coerce(X, :var1 => Continuous)`  |\n",
    "| Inferencia automática                 | Usar `autotype()`        | `autotype(X)`                         |\n",
    "| Comprobar los tipos científicos actuales | Usar `schema()`          | `schema(X)`                           |\n",
    "\n",
    "### Qué ocurre si se omite `coerce`\n",
    "\n",
    "Si se omite el paso de coerción:\n",
    "\n",
    "* **MLJ puede interpretar incorrectamente la variable objetivo** como continua, impidiendo el uso de modelos de clasificación.  \n",
    "* **Algunos algoritmos** (por ejemplo, *DecisionTree*, *NaiveBayes*) pueden **fallar o generar predicciones incorrectas**.  \n",
    "* La función `machine()` puede **rechazar la vinculación entre el modelo y los datos** si los tipos no son compatibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b376d4",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "\n",
    "Siguiendo estas líneas, se presentan varios ejemplos de cómo utilizar el nuevo **Voting Classifier** que hemos implementado.\n",
    "\n",
    "En ejemplos previos, construimos el *ensemble* de la siguiente manera:\n",
    "\n",
    "```julia\n",
    "voting_hard = VotingClassifier(models=base_models_list, voting=:hard)\n",
    "voting_soft = VotingClassifier(models=base_models_list, voting=:soft)\n",
    "\n",
    "mach_hard = machine(voting_hard, train_input, train_output) |> fit!\n",
    "mach_soft = machine(voting_soft, train_input, train_output) |> fit!\n",
    "```\n",
    "\n",
    "* `voting=:hard` → utiliza votación mayoritaria (basada en las etiquetas de clase).  \n",
    "\n",
    "* `voting=:soft` → utiliza votación por promedio de probabilidades (requiere modelos que generen probabilidades como salida).  \n",
    "\n",
    "Los siguientes ejemplos muestran cómo **modificar e integrar dinámicamente** el `VotingClassifier` dentro de tu flujo de trabajo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45bc191",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplo 1: Cambio dinámico del tipo de votación\n",
    "ensemble = VotingClassifier(models=base_models_list, voting=:hard)\n",
    "println(\"\\nTipo de votación actual: $(ensemble.voting)\")\n",
    "\n",
    "ensemble.voting = :soft\n",
    "println(\"Tipo de votación actual: $(ensemble.voting)\n",
    "\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a28c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2: Uso del `VotingClassifier` en una *Pipeline*\n",
    "pipe_hard = @pipeline(\n",
    "    Standardizer(),\n",
    "    VotingClassifier(models=base_models_list, voting=:hard)\n",
    ")\n",
    "\n",
    "pipe_soft = @pipeline(\n",
    "    Standardizer(),\n",
    "    VotingClassifier(models=base_models_list, voting=:soft)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade52dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 3: Validación cruzada comparando ambas estrategias de votación\n",
    "cv_hard = evaluate!(\n",
    "    machine(voting_hard, train_input, train_output),\n",
    "    resampling=CV(nfolds=5),\n",
    "    measure=accuracy\n",
    ")\n",
    "println(\"Hard Voting CV accuracy: $(round(mean(cv_hard.measurement)*100, digits=2)) %\")\n",
    "\n",
    "cv_soft = evaluate!(\n",
    "    machine(voting_soft, train_input, train_output),\n",
    "    resampling=CV(nfolds=5),\n",
    "    measure=accuracy\n",
    ")\n",
    "println(\"Soft Voting CV accuracy: $(round(mean(cv_soft.measurement)*100, digits=2)) %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.1",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Definiciones de tipos Julia e integración con MLJ\n",
        "\n",
        "Este cuaderno tiene como objetivo introducir algunos conceptos fundamentales de Julia y del ecosistema **MLJ.jl**. En primer lugar, se explica que en Julia no existen objetos en el sentido clásico de la programación orientada a objetos (OOP), pero es posible **simular comportamientos similares** mediante el uso de `mutable struct`, funciones y el mecanismo de *multiple dispatch*. A continuación, se presenta el flujo de trabajo con **MLJ**, destacando cómo en las prácticas puede ser necesario desarrollar **adaptaciones o módulos propios** para integrar nuevos modelos o transformadores. Finalmente, se incluyen ejemplos prácticos que ilustran el uso de **Grid Search** (búsqueda en rejilla de hiperparámetros) y la construcción de **pipelines** en MLJ, combinando transformaciones y modelos de aprendizaje automático en un flujo coherente y reproducible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como siempre lo primero es garantizar que tenemos todos los elementos que nos pueden hacer falta en la ejecución del notebook. \n",
        "> Ejecuta la siguiente celda para activar el proyecto y añadir (si fuese necesario) las dependencias que usaremos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "using Pkg\n",
        "Pkg.activate(\".\")\n",
        "Pkg.add([\"MLJ\", \"MLJModels\", \"DecisionTree\", \"MultivariateStats\", \"StatsBase\", \"RDatasets\", \"MLJModelInterface\", \"HypothesisTests\", \"Tables\", \"CategoricalArrays\", \"MLJBase\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Los \"Objetos\" en Julia\n",
        "\n",
        "Julia no es un lenguaje *estrictamente orientado a objetos* como Java, C++ o Python. En lugar de centrar su diseño en la encapsulación y la herencia, Julia se apoya en el concepto de **envío múltiple** (*multiple dispatch*) y en la composición de **tipos de datos** (`struct` y `mutable struct`) con **funciones genéricas**. Esta filosofía permite escribir código más flexible, extensible y eficiente, sin necesidad de estructuras jerárquicas rígidas.\n",
        "\n",
        "En Julia, un `struct` define un **tipo de dato inmutable**, es decir, una colección de campos que no pueden modificarse una vez creada la instancia. Por otro lado, un `mutable struct` es equivalente a un tipo con campos modificables, lo que se asemeja más a los “objetos” de los lenguajes orientados a objetos clásicos. La diferencia clave es que los métodos no se definen dentro del tipo, sino que se declaran como **funciones independientes** que “saben” operar sobre determinados tipos de datos.\n",
        "\n",
        "En este modelo, las **funciones** actúan como los verdaderos puntos de extensión del lenguaje: pueden tener múltiples implementaciones (métodos) que se eligen dinámicamente según los **tipos de los argumentos**. Este mecanismo, conocido como *multiple dispatch*, es una generalización del polimorfismo clásico de la POO, donde la selección del método depende del tipo de **todos** los argumentos, no solo del primero (como ocurre con el `self` o `this` en OOP).\n",
        "\n",
        "Para lograr un estilo de programación “similar” a la orientación a objetos, es habitual definir funciones cuyo **primer argumento** sea la instancia de un tipo sobre la que se quiere operar, lo que da una apariencia de “método asociado”. Por ejemplo, podríamos tener `deposit!(cuenta, cantidad)` o `move!(robot, paso)`, donde la función representa la operación y el tipo determina el comportamiento concreto.\n",
        "\n",
        "Si lo pensamos desde una perspectiva más conceptual, Julia se asemeja en cierto modo al modelo de **envío de mensajes** de Objective-C: las funciones serían los “mensajes” y los tipos, las entidades que saben cómo responder a ellos. Así, cada combinación de tipos define su propia lógica, lo que permite crear sistemas altamente modulares y expresivos, sin necesidad de herencia o clases tradicionales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Ejemplo genérico con `mutable struct`\n",
        "Definimos una cuenta bancaria con operaciones típicas. Incluimos **constructores** (externos e internos) y métodos \"asociados\" vía *multiple dispatch*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "module EjemploBanco\n",
        "export CuentaBancaria, depositar!, retirar!, balance\n",
        "\n",
        "mutable struct CuentaBancaria\n",
        "    titular::String\n",
        "    _balance::Float64\n",
        "\n",
        "    # Constructor interno (valida invariantes/argumentos)\n",
        "    function CuentaBancaria(titular::String, balance_inicial::Real)\n",
        "        balance_inicial < 0 && error(\"El balance no puede ser negativo\"))\n",
        "        new(titular, float(balance_inicial))\n",
        "    end\n",
        "end\n",
        "\n",
        "# Constructor externo de conveniencia\n",
        "CuentaBancaria(titular::AbstractString) = CuentaBancaria(String(titular), 0.0)\n",
        "\n",
        "# \"Métodos asociados\" mediante multiple dispatch\n",
        "function depositar!(cuenta::CuentaBancaria, cantidad::Real)\n",
        "    cantidad <= 0 && error(\"La cantidad a ingresar debe ser positiva\"))\n",
        "    cuenta._balance += float(cantidad)\n",
        "    return cuenta\n",
        "end\n",
        "\n",
        "function retirar!(cuenta::CuentaBancaria, cantidad::Real)\n",
        "    cantidad <= 0 && error(\"La cantidad a retirar debe ser positiva\"))\n",
        "    cantidad > cuenta._balance && error(cantidad, \"Fondos insuficientes\"))\n",
        "    cuenta._balance -= float(cantidad)\n",
        "    return cuenta\n",
        "end\n",
        "\n",
        "balance(c::CuentaBancaria) = c._balance\n",
        "\n",
        "# Personalizamos la impresión\n",
        "Base.show(io::IO, cuenta::CuentaBancaria) =\n",
        "    print(io, \"CuentaBancaria(titular='\", cuenta.titular, \"', balance=\", cuenta._balance, \")\")\n",
        "\n",
        "end # module\n",
        "\n",
        "using .EjemploBanco\n",
        "cuenta_cucufate = CuentaBancaria(\"Cucufate\", 100.0)\n",
        "depositar!(cuenta_ccucufate, 50)\n",
        "retirar!(cuenta_cucufate, 20)\n",
        "println(cuenta_cucufate)\n",
        "println(\"Balance actual: \", balance(c))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5230c45",
      "metadata": {},
      "source": [
        "### Constructores y métodos “al estilo Objective‑C”\n",
        "Hay algunos elementos a destacar de este código en concreto serían:\n",
        "- **Constructores internos**: permiten validar elementos o condiciones invariantes antes de crear la instancia (`new`).\n",
        "- **Constructores externos**: funciones con el mismo nombre del tipo que delegan en el interno y aportan *azúcar sintáctico* para simplificar la creación\n",
        "- **Múltiple despacho**: define funciones con distintos métodos especializados por tipo. La *asociación* \"tipo→método\" la da el **tipo del primer argumento**.\n",
        "\n",
        "Finalmente, se puede **agrupar** los tipos y sus funciones en un **módulo**, logrando *namespacing* y organización similar a *clases/paquetes* en otros lenguajes.\n",
        "\n",
        "A continuación veamos un ejemplo en el que se aplica la herencia entre tipos\n",
        "> Lo primero, reinicia el kernel porque vamos a usar nombres similares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879b8ee4",
      "metadata": {},
      "outputs": [],
      "source": [
        "module HerenciaBancaria\n",
        "export Cuenta, CuentaBancaria, CuentaAhorro, depositar!, retirar!, balance\n",
        "\n",
        "# Tipo abstracto: actúa como “superclase”\n",
        "abstract type Cuenta end\n",
        "\n",
        "# Tipo base: una cuenta genérica\n",
        "mutable struct CuentaBancaria <: Cuenta\n",
        "    titular::String\n",
        "    _balance::Float64\n",
        "end\n",
        "\n",
        "# Subtipo: una cuenta de ahorro con intereses\n",
        "mutable struct CuentaAhorro <: Cuenta\n",
        "    titular::String\n",
        "    _balance::Float64\n",
        "    interes::Float64\n",
        "end\n",
        "\n",
        "# --- Métodos genéricos ---\n",
        "\n",
        "\"Devuelve el balance de cualquier tipo de cuenta.\"\n",
        "balance(cuenta::CuentaBancaria) = cuenta._balance\n",
        "balance(cuenta::CuentaAhorro) = cuenta._balance\n",
        "\n",
        "\"Depósito genérico (válido para cualquier subtipo de Cuenta).\"\n",
        "function depositar!(cuenta::Cuenta, cantidad::Real)\n",
        "    cantidad <= 0 && error(\"La cantidad a ingresar debe ser positiva\")\n",
        "    cuenta._balance += float(cantidad)\n",
        "    return cuenta\n",
        "end\n",
        "\n",
        "\"Retirada genérica (con posible redefinición para subtipos).\"\n",
        "function retirar!(cuenta::Cuenta, cantidad::Real)\n",
        "    cantidad <= 0 && error(\"La cantidad a retirar debe ser positiva\")\n",
        "    cantidad > cuenta._balance && error(cantidad, \"Fondos insuficientes\")\n",
        "    cuenta._balance -= float(cantidad)\n",
        "    return cuenta\n",
        "end\n",
        "\n",
        "# --- Polimorfismo: redefinición para CuentaAhorro ---\n",
        "\n",
        "\"\"\"\n",
        "En las cuentas de ahorro, cada vez que se hace un depósito\n",
        "se aplica un pequeño interés adicional.\n",
        "\"\"\"\n",
        "function depositar!(cuentaAhorro::CuentaAhorro, cantidad::Real)\n",
        "    cantidad <= 0 && error(\"La cantidad a ingresar debe ser positiva\")\n",
        "    bonificado = cantidad * (1 + cuentaAhorro.interes)\n",
        "    cuentaAhorro._balance += float(bonificado)\n",
        "    return cuentaAhorro\n",
        "end\n",
        "\n",
        "# --- Personalización de impresión ---\n",
        "Base.show(io::IO, cuentaBancaria::CuentaBancaria) =\n",
        "    print(io, \"CuentaBancaria(titular='\", cuentaBancaria.titular, \"', balance=\", cuentaBancaria._balance, \")\")\n",
        "\n",
        "Base.show(io::IO, cuentaAhorro::CuentaAhorro) =\n",
        "    print(io, \"CuentaAhorro(titular='\", cuentaAhorro.titular, \"', balance=\", cuentaAhorro._balance, \", interes=\", cuentaAhorro.interes, \")\")\n",
        "\n",
        "end # module\n",
        "\n",
        "using .HerenciaBancaria\n",
        "\n",
        "# Creamos instancias de distintos tipos\n",
        "c_cucufate = CuentaBancaria(\"Cucufate\", 100.0)\n",
        "c_isidora= CuentaAhorro(\"Isidora\", 100.0, 0.05)\n",
        "\n",
        "depositar!(c_cucufate, 100)\n",
        "depositar!(c_isidora, 100)\n",
        "\n",
        "println(c_cucufate)\n",
        "println(c_isidora)\n",
        "\n",
        "retirar!(c_cucufate, 50)\n",
        "retirar!(c_isidora, 30)\n",
        "\n",
        "println(\"Balances finales:\")\n",
        "println(\"Cuenta normal: \", balance(c_cucufate))\n",
        "println(\"Cuenta ahorro: \", balance(c_isidora))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En Julia no existe la **herencia clásica** de los lenguajes orientados a objetos (como Java, C++ o Python), pero sí se puede construir una **jerarquía de tipos** mediante el uso de **tipos abstractos** y el operador `<:`.  \n",
        "\n",
        "Un **tipo abstracto** actúa como una “superclase” conceptual: no se puede instanciar directamente, pero sirve para agrupar un conjunto de tipos que comparten una cierta interfaz o comportamiento común.  \n",
        "Los **tipos concretos** (definidos con `struct` o `mutable struct`) pueden declararse como *subtipos* de ese tipo abstracto, lo que permite que las funciones definidas sobre el tipo abstracto\n",
        "\n",
        "### Objetos y métodos genéricos y paramétricos\n",
        "Otro de los elementos que permite está flexibilidad es la creación de elementos genéricos o parametrizadas como por ejemplo el siguiente contenedor con *setter/getter* mutables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "module ContainerExample\n",
        "export Box\n",
        "\n",
        "mutable struct Box{T}\n",
        "    value::T\n",
        "end\n",
        "\n",
        "Box(x) = Box{typeof(x)}(x)\n",
        "\n",
        "setvalue!(b::Box{T}, x::T) where {T} = (b.value = x; b)\n",
        "getvalue(b::Box) = b.value\n",
        "\n",
        "end # module\n",
        "\n",
        "using .ContainerExample\n",
        "b = Box(42)\n",
        "println(ContainerExample.getvalue(b))\n",
        "ContainerExample.setvalue!(b, 100)\n",
        "println(ContainerExample.getvalue(b))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a0b4780",
      "metadata": {},
      "source": [
        "En este ejemplo, el tipo `Box{T}` es **paramétrico**, lo que significa que el tipo de los valores que contiene (`T`) se especifica al crear una instancia. Por ejemplo, `Box(42)` crea una `Box{Int64}`, mientras que `Box(\"hola\")` sería una `Box{String}`. Esto permite que el mismo código funcione con distintos tipos, manteniendo la seguridad de tipos en tiempo de compilación.\n",
        "\n",
        "La función `setvalue!` usa `where {T}` para indicar que `T` es un parámetro de tipo genérico que se introduce en el contexto de la función. En otras palabras, `T` se “hereda” del tipo del argumento `b`  (es decir, del `Box{T}`), y se exige que el nuevo valor `x` sea del mismo tipo `T`. Así se evita, por ejemplo, intentar asignar un string a una `Box{Int}`.\n",
        "\n",
        "Este mecanismo de tipos paramétricos con where es una de las características más potentes de Julia, ya que combina la flexibilidad del polimorfismo genérico con la eficiencia de la compilación estática, permitiendo que el compilador genere código optimizado para cada tipo concreto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dcac2a0",
      "metadata": {},
      "source": [
        "Para poder usar cualquiera de estos módulos, se puede directamente volcar el código a un fichero, por ejemplo, `Container.jl` y para usarlo solo harían falta las siguientes líneas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10801e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "include(\"Contaniner.jl\")\n",
        "using .ContainerExample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prácticas con **MLJ.jl**: adaptaciones y módulos\n",
        "Durante las prácticas vamos a usar la librería **MLJ**, esta hace uso del mecanismo de herencia descrito con anterioridad para los diferentes modelos y módulos. En MLJ, los **modelos** se representan como **tipos** livianos (habitualmente `struct`/`mutable struct`) que describen **hiperparámetros**. La lógica de *ajuste* y *predicción* se implementa a través de las funciones del **`MLJModelInterface`**. \n",
        "\n",
        "Cuando se desea **incluir un modelo propio** (porque no existe en el *registry* de MLJ o quieres adaptar una función nativa de Julia), es buena práctica **encapsularlo en un módulo** para mantener el *namespacing*.\n",
        "\n",
        "Abajo tienes un ejemplo mínimo de un **regresor determinista** que predice la **media** de *y* (útil como *baseline*), definido con `@mlj_model` y las funciones requeridas por la interfaz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350db67c",
      "metadata": {},
      "outputs": [],
      "source": [
        "module MyToyModels\n",
        "using MLJModelInterface\n",
        "using Statistics\n",
        "\n",
        "# Declaramos un modelo determinista muy simple con metadatos mínimos.\n",
        "@mlj_model mutable struct MeanRegressor <: MLJModelInterface.Deterministic\n",
        "    # Hiperparámetros (si hubiera) irían aquí como campos con valores por defecto.\n",
        "end\n",
        "\n",
        "# Ajuste del modelo: devolvemos el estado entrenado (fitresult), un caché y un reporte.\n",
        "function MLJModelInterface.fit(model::MeanRegressor, verbosity::Int, X, y)\n",
        "    μ = Statistics.mean(skipmissing(y))\n",
        "    fitresult = (mu = μ,)\n",
        "    cache = nothing\n",
        "    report = (;)\n",
        "    return fitresult, cache, report\n",
        "end\n",
        "\n",
        "# Predicción: repetimos la media tantas veces como filas en X.\n",
        "function MLJModelInterface.predict(model::MeanRegressor, fitresult, Xnew)\n",
        "    n = MLJModelInterface.nrows(Xnew)\n",
        "    return fill(fitresult.mu, n)\n",
        "end\n",
        "\n",
        "end # module\n",
        "\n",
        "using MLJ\n",
        "import .MyToyModels: MeanRegressor\n",
        "\n",
        "# Datos sintéticos simples\n",
        "X = (x1 = rand(100), x2 = rand(100))\n",
        "y = 3 .* X.x1 .- 2 .* X.x2 .+ 0.1 .* randn(100)\n",
        "\n",
        "m = MeanRegressor()\n",
        "mach = machine(m, X, y)\n",
        "fit!(mach)\n",
        "ŷ = predict(mach, X)\n",
        "println(\"Primeras 5 predicciones (constantes): \", ŷ[1:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1beff4e",
      "metadata": {},
      "source": [
        "### ¿Qué hace `@mlj_model` en MLJ?\n",
        "\n",
        "La macro `@mlj_model` forma parte del paquete **MLJModelInterface.jl** y se utiliza para declarar un nuevo tipo de modelo que sea **compatible con el ecosistema MLJ**.\n",
        "\n",
        "la macro realiza varias tareas automáticamente:\n",
        "\n",
        "1. **Registra el tipo como modelo MLJ**: marca la estructura `MeanRegressor` como un modelo reconocible por MLJ (de tipo `Deterministic`, `Probabilistic`, `Unsupervised`, etc.).\n",
        "   Esto permite luego usarlo directamente con funciones como `machine`, `fit!`, `predict`, `evaluate!`, etc.\n",
        "\n",
        "2. **Asigna metadatos internos** (como nombre, tipo de modelo, campos, etc.) necesarios para la integración con MLJ.\n",
        "   Por ejemplo, permite que MLJ sepa cuáles son los hiperparámetros del modelo (`fields` del struct) y cómo incluirlos en operaciones como `TunedModel` (búsqueda de hiperparámetros).\n",
        "\n",
        "3. **Facilita la interoperabilidad**: los modelos declarados con `@mlj_model` se comportan igual que los modelos integrados de MLJ, por lo que se pueden incluir en pipelines, validaciones cruzadas y experimentos de comparación.\n",
        "\n",
        "#### Tipos de modelos disponibles en `MLJModelInterface`\n",
        "\n",
        "Al declarar un modelo con `@mlj_model`, se debe indicar a qué tipo general pertenece mediante herencia de uno de los **tipos abstractos** definidos en `MLJModelInterface`.  \n",
        "Esta clasificación le dice a MLJ cómo debe tratar el modelo (por ejemplo, si necesita `fit!` y `predict`, si genera distribuciones, si transforma datos, etc.).\n",
        "\n",
        "Los principales tipos disponibles son los siguientes:\n",
        "\n",
        "##### 1. `Deterministic`\n",
        "Modelos **supervisados** que producen una **predicción única y determinista** para cada observación.\n",
        "- Ejemplo: regresores lineales, árboles de decisión, SVM, redes neuronales.\n",
        "- Deben implementar al menos:\n",
        "  - `fit(model, verbosity, X, y)`\n",
        "  - `predict(model, fitresult, Xnew)`\n",
        "\n",
        "##### 2. `Probabilistic`\n",
        "Modelos **supervisados** que devuelven **distribuciones de probabilidad** en lugar de valores puntuales.\n",
        "- Ejemplo: regresión bayesiana, clasificadores probabilísticos, GaussianNB.\n",
        "- Deben implementar:\n",
        "  - `fit(model, verbosity, X, y)`\n",
        "  - `predict(model, fitresult, Xnew)` → devuelve `Distribution` (una por observación).\n",
        "\n",
        "##### 3. `Unsupervised`\n",
        "Modelos **no supervisados**, que no utilizan `y` durante el entrenamiento (por ejemplo, clustering o reducción de dimensionalidad).\n",
        "- Ejemplo: `KMeans`, `PCA`, `ICA`.\n",
        "- Deben implementar:\n",
        "  - `fit(model, verbosity, X)`\n",
        "  - `transform(model, fitresult, Xnew)`\n",
        "\n",
        "##### 4. `Static`\n",
        "Modelos que **no necesitan entrenamiento**; su salida depende solo de los datos de entrada.\n",
        "- Ejemplo: funciones de transformación o normalización fija.\n",
        "\n",
        "##### 5. `Supervised`\n",
        "Es una **superclase abstracta** que engloba a los modelos supervisados (`Deterministic` y `Probabilistic`).\n",
        "No se usa directamente, pero puede servir como tipo intermedio en jerarquías personalizadas.\n",
        "\n",
        "##### 6. `UnsupervisedNetwork` y otros tipos especializados\n",
        "Existen además tipos más específicos definidos para tareas concretas o experimentales, como:\n",
        "- `UnsupervisedNetwork` (para modelos de grafos sin supervisión)\n",
        "- `NetworkDeterministic` o `NetworkProbabilistic` (para modelos neuronales, en `MLJFlux`)\n",
        "\n",
        "---\n",
        "\n",
        "En resumen:\n",
        "| Tipo | Supervisión | Devuelve | Métodos clave |\n",
        "|------|--------------|-----------|----------------|\n",
        "| `Deterministic` | Sí | Valor único | `fit`, `predict` |\n",
        "| `Probabilistic` | Sí | Distribución | `fit`, `predict` |\n",
        "| `Unsupervised` | No | Datos transformados | `fit`, `transform` |\n",
        "| `Static` | Opcional | Resultado directo | `transform` |\n",
        "| `Supervised` | Abstracto | — | — |\n",
        "\n",
        "Estos tipos permiten que MLJ integre modelos de distintos paquetes de forma uniforme y sepa **cómo combinarlos en pipelines, evaluaciones y ajustes automáticos de hiperparámetros**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transformador **ANOVAFilter (SelectKBest)**\n",
        "\n",
        "Como ejemplo de **adaptación** en MLJ, añadimos un **filtro supervisado por ANOVA** que selecciona las *k* mejores características según el **estadístico F** de un test ANOVA de un factor.\n",
        "\n",
        "A continuación se muestra la implementación siguiendo la **interfaz de modelos de MLJ** (`MLJModelInterface`). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "module MyFilters\n",
        "using MLJ, MLJBase, MLJModelInterface, Tables, HypothesisTests, CategoricalArrays\n",
        "\n",
        "export ANOVAFilter\n",
        "\n",
        "# --- Definición de transformador ANOVA SelectKBest ---\n",
        "mutable struct ANOVAFilter <: MLJModelInterface.Supervised\n",
        "    k::Int\n",
        "end\n",
        "\n",
        "# Constructor con argumentos por nombre (estilo MLJ)\n",
        "ANOVAFilter(; k::Int=2) = ANOVAFilter(k)\n",
        "\n",
        "import MLJModelInterface: fit, transform, input_scitype, target_scitype, output_scitype\n",
        "\n",
        "function fit(model::ANOVAFilter, verbosity::Int, X, y)\n",
        "    # Convertir X a matriz y asegurarse que es Float64\n",
        "    Xmat = Float64.(MLJBase.matrix(X))\n",
        "\n",
        "    # Convertir y a vector numérico si es categórico\n",
        "    y_numeric = y isa CategoricalVector ? Int.(levelcode.(y)) : Int.(y)\n",
        "\n",
        "    # Calcular F-statistics usando HypothesisTests\n",
        "    n_features = size(Xmat, 2)\n",
        "    fstats = zeros(Float64, n_features)\n",
        "\n",
        "    for j in 1:n_features\n",
        "        feature = Xmat[:, j]\n",
        "\n",
        "        # Agrupar datos por clase\n",
        "        classes = unique(y_numeric)\n",
        "        groups = [feature[y_numeric .== c] for c in classes]\n",
        "\n",
        "        # Filtrar grupos vacíos\n",
        "        groups = filter(g -> length(g) > 0, groups)\n",
        "\n",
        "        if length(groups) < 2\n",
        "            fstats[j] = 0.0\n",
        "            continue\n",
        "        end\n",
        "\n",
        "        try\n",
        "            # Crear test ANOVA\n",
        "            test = OneWayANOVATest(groups...)\n",
        "            # Nota: según la versión de HypothesisTests, los campos internos pueden variar.\n",
        "            # Aquí seguimos el patrón del ejemplo proporcionado por el usuario.\n",
        "            MSt = test.SStᵢ / test.DFt  # Mean square treatment (between)\n",
        "            MSe = test.SSeᵢ / test.DFe  # Mean square error (within)\n",
        "            fstats[j] = MSt / MSe\n",
        "        catch e\n",
        "            # Si hay algún error en el cálculo, asignar 0\n",
        "            fstats[j] = 0.0\n",
        "        end\n",
        "    end\n",
        "\n",
        "    # Seleccionar top k features con mayor F-statistic\n",
        "    k_actual = min(model.k, n_features)\n",
        "    idxs = sortperm(fstats, rev=true)[1:k_actual]\n",
        "\n",
        "    # Guardar los nombres de las columnas originales\n",
        "    feature_names = collect(Tables.columnnames(X))\n",
        "    selected_names = [feature_names[i] for i in idxs]\n",
        "\n",
        "    # IMPORTANTE: fitresult debe contener la info necesaria para transform\n",
        "    fitresult = (idxs=idxs, selected_names=selected_names)\n",
        "    cache = nothing\n",
        "    report = (fstats=fstats, idxs=idxs, selected_features=selected_names)\n",
        "\n",
        "    return fitresult, cache, report\n",
        "end\n",
        "\n",
        "function transform(model::ANOVAFilter, fitresult, X)\n",
        "    # Convertir X a matriz\n",
        "    Xmat = MLJBase.matrix(X)\n",
        "    # Seleccionar columnas usando fitresult (no cache)\n",
        "    X_selected = Xmat[:, fitresult.idxs]\n",
        "    # Convertir de vuelta a tabla con nombres apropiados\n",
        "    return MLJBase.table(X_selected, names=fitresult.selected_names)\n",
        "end\n",
        "\n",
        "input_scitype(::Type{<:ANOVAFilter}) = Table(Continuous)\n",
        "target_scitype(::Type{<:ANOVAFilter}) = AbstractVector{<:Finite}\n",
        "output_scitype(::Type{<:ANOVAFilter}) = Table(Continuous)\n",
        "\n",
        "end # module\n",
        "\n",
        "using .MyFilters\n",
        "println(\"ANOVAFilter disponible: \", MyFilters.ANOVAFilter())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ¿Por qué `ANOVAFilter` no usa `@mlj_model`?\n",
        "\n",
        "En este caso, `ANOVAFilter` **no necesita** la macro `@mlj_model` porque ya se está definiendo **manualmente** toda la interfaz requerida por MLJ mediante las funciones del módulo `MLJModelInterface` (`fit`, `transform`, `input_scitype`, etc.).  \n",
        "\n",
        "La macro `@mlj_model` se utiliza principalmente como **atajo** o **azúcar sintáctico** para registrar modelos nuevos que se ajustan a la estructura estándar de MLJ, especialmente **regresores o clasificadores** (es decir, modelos supervisados que implementan `fit` y `predict`).  \n",
        "En esos casos, la macro se encarga de:\n",
        "- Registrar el tipo del modelo en la metainformación de MLJ.\n",
        "- Añadir automáticamente metadatos sobre sus hiperparámetros.\n",
        "- Facilitar su compatibilidad con herramientas como `TunedModel`, `evaluate!` o `modelinfo`.\n",
        "\n",
        "Sin embargo, `ANOVAFilter` es un **transformador**, no un modelo predictivo.  \n",
        "Su función es **filtrar y transformar características**, no producir predicciones.  \n",
        "Por tanto, sigue el patrón de un **modelo de preprocesamiento supervisado** (como un `FeatureSelector`, `Standardizer` o `PCA`), donde se define explícitamente:\n",
        "\n",
        "- `fit(model, verbosity, X, y)` → el transformador o estimador y devuelve una **tupla** `(fitresult, cache, report)`. Aprende que columnas conservar.\n",
        "  - `fitresult` debe contener *todo lo necesario* para aplicar `transform` o `predict` después.\n",
        "  - `cache` se usa para guardar datos intermedios opcionales.\n",
        "  - `report` incluye información diagnóstica (por ejemplo, los F-stats por característica).  \n",
        "- `transform(model, fitresult, Xnew)` → aplica la **transformación** aprendida en `fitresult` a nuevos datos. \n",
        "- `input_scitype`, `target_scitype` y `output_scitype` → describen los tipos científicos de entrada, salida y variable objetivo.\n",
        " - `input_scitype(::Type{<:MyModel})`: el **tipo científico** esperado para la **entrada** (por ejemplo `Table(Continuous)`).\n",
        " - `target_scitype(::Type{<:MyModel})`: el **tipo científico** esperado para el **objetivo** `y` (por ejemplo `AbstractVector{<:Finite}` para clasificación).\n",
        " - `output_scitype(::Type{<:MyModel})`: el **tipo científico** de la **salida** tras `transform`.\n",
        " Estas *restricciones de scitype* ayudan a MLJ a **componer** correctamente *pipelines*, realizar **validaciones** y detectar **incompatibilidades** temprano.\n",
        "\n",
        "Al implementar estas funciones directamente, el modelo ya es completamente **compatible con MLJ** sin necesidad de la macro.  \n",
        "De hecho, MLJ detecta y usa cualquier tipo que implemente la interfaz mínima de `fit`/`transform` o `fit`/`predict`, independientemente de si fue declarado con `@mlj_model` o no.\n",
        "\n",
        "En resumen:\n",
        "- ✅ Usa `@mlj_model` → cuando defines **modelos predictivos (supervisados)** como regresores o clasificadores.\n",
        "- ❌ No es necesario para **transformadores o preprocesadores**, si ya defines manualmente los métodos de la interfaz.\n",
        "\n",
        "Esto da más flexibilidad y control sobre el comportamiento del modelo, especialmente cuando se trata de componentes personalizados dentro de *pipelines*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Uso del pipeline\n",
        "Podemos encadenar el filtro con otros elementos dentro de MLJ. También podremos hacer *grid search* sobre el hiperparámetro `k`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "using MLJ, MLJModels, MLJBase, RDatasets, CategoricalArrays, DataFrames\n",
        "\n",
        "Standarizer = @load Standardizer pkg=MLJModels\n",
        "DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree\n",
        "\n",
        "iris = dataset(\"datasets\", \"iris\")\n",
        "y = categorical(iris.Species)\n",
        "X = RDatasets.select(iris, DataFrames.Not(:Species))\n",
        "\n",
        "\n",
        "pipe = MLJBase.Pipeline(\n",
        "  scaler=Standardizer(),\n",
        "  classifier=DecisionTreeClassifier()\n",
        ")\n",
        "\n",
        "mach = MLJ.machine(pipe, X, y)  |> MLJ.fit!\n",
        "X_pre = MLJ.predict(mach, X)\n",
        "println(X_pre[1:2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc81aa01",
      "metadata": {},
      "source": [
        "Sin embargo, la composición con el operador `|>` sólo permite **un único modelo supervisado** (es decir, uno que use `y` durante el entrenamiento).  \n",
        "Como `ANOVAFilter` es un **transformador supervisado** —necesita conocer las etiquetas `y` para calcular la importancia de las variables— y el **clasificador** también es supervisado, el operador `|>` no sirve.\n",
        "\n",
        "Para resolver esto, se usa una **Learning Network**, que permite definir explícitamente cómo se conectan las distintas etapas de un modelo compuesto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35c4b742",
      "metadata": {},
      "outputs": [],
      "source": [
        "using MLJ, MLJModels, DataFrames, RDatasets, CategoricalArrays\n",
        "using .MyFilters  # tu módulo con ANOVAFilter(k::Int)\n",
        "\n",
        "# Cargar modelos\n",
        "Standardizer = @load Standardizer pkg=MLJModels\n",
        "DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree\n",
        "\n",
        "import MLJBase\n",
        "import MLJBase: source, machine, node  # utilidades de la learning network\n",
        "\n",
        "\"\"\"\n",
        "Pipeline: Standardizer -> ANOVAFilter (supervisado) -> Clasificador\n",
        "(Probabilístico porque DecisionTreeClassifier devuelve distribuciones)\n",
        "\"\"\"\n",
        "mutable struct ANOVA_Pipeline <: MLJBase.ProbabilisticNetworkComposite\n",
        "    scaler\n",
        "    selector\n",
        "    classifier\n",
        "end\n",
        "\n",
        "function MLJBase.prefit(model::ANOVA_Pipeline, verbosity, X, y)\n",
        "    Xs = source(X)\n",
        "    ys = source(y)\n",
        "\n",
        "    m_scaler   = machine(:scaler, Xs)\n",
        "    Z1         = MLJ.transform(m_scaler, Xs)          \n",
        "\n",
        "    m_selector = machine(:selector, Z1, ys)           # supervisado\n",
        "    Z2         = MLJ.transform(m_selector, Z1)        \n",
        "\n",
        "    m_clf      = machine(:classifier, Z2, ys)\n",
        "    yhat       = MLJ.predict(m_clf, Z2)              \n",
        "\n",
        "    return (\n",
        "        predict = yhat,                                # operación exportada\n",
        "        report  = (selector = node(report, m_selector),) # report como nodo\n",
        "    )\n",
        "end\n",
        "\n",
        "# ----------------------------\n",
        "# Datos y uso\n",
        "# ----------------------------\n",
        "iris = RDatasets.dataset(\"datasets\", \"iris\")\n",
        "y = categorical(iris.Species)\n",
        "X = DataFrames.select(iris, DataFrames.Not(:Species))  # evita ambigüedad\n",
        "\n",
        "pipe = ANOVA_Pipeline(\n",
        "    Standardizer(),\n",
        "    MyFilters.ANOVAFilter(k=2),\n",
        "    DecisionTreeClassifier()\n",
        ")\n",
        "\n",
        "mach = machine(pipe, X, y)\n",
        "MLJ.fit!(mach)                         # calificado para evitar choques\n",
        "ŷ = MLJ.predict(mach, X)\n",
        "\n",
        "println(ŷ[1:2])\n",
        "println(\"Features seleccionadas por ANOVA: \",\n",
        "        report(mach).selector.selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "584239c2",
      "metadata": {},
      "source": [
        "En la función `prefit` se especifica cómo fluyen los datos entre las etapas:\n",
        "\n",
        "* `source(X)` y `source(y)` definen los nodos de entrada de la red.\n",
        "\n",
        "* Cada `machine` representa una etapa entrenable (modelo o transformador).\n",
        "\n",
        "* El prefit devuelve una tupla con los elementos que se quieren exponer al exterior:\n",
        "\n",
        "  * predict = yhat: indica que el modelo compuesto implementa el método predict.\n",
        "\n",
        "  * report = (selector = node(report, m_selector),): permite acceder al informe (report) del transformador interno una vez entrenado.\n",
        "\n",
        "\n",
        "\n",
        "#### Aspectos técnicos importantes\n",
        "\n",
        "* Calificación de funciones: se usa MLJ.transform y MLJ.predict dentro de prefit para evitar ambigüedades con funciones de otros paquetes (como DataFrames.transform).\n",
        "\n",
        "* Uso de node(report, m_selector): en una Learning Network, los componentes aún no están entrenados durante la definición, por lo que no se puede acceder a sus resultados directamente.\n",
        "  La función node crea un “enlace diferido” que se resuelve automáticamente tras el fit!.\n",
        "\n",
        "* Probabilistic vs Deterministic: el supertipo (ProbabilisticNetworkComposite o DeterministicNetworkComposite) debe coincidir con el tipo de salida del clasificador final.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search y Pipelines en **MLJ**\n",
        "\n",
        "Una vez construido el pipeline, podemos mejorar su rendimiento ajustando los **hiperparámetros** de las distintas etapas.  \n",
        "MLJ proporciona el tipo `TunedModel`, que permite **automatizar la búsqueda del mejor conjunto de parámetros** mediante diferentes estrategias de optimización, como búsqueda en rejilla (*Grid Search*), aleatoria (*Random Search*), o métodos bayesianos (*Bayesian Optimization*).\n",
        "\n",
        "En este ejemplo usamos una **búsqueda en rejilla (Grid Search)** combinada con **validación cruzada (Cross-Validation)** para encontrar los mejores valores de:\n",
        "\n",
        "- `pca.maxoutdim`: número de componentes principales a conservar.  \n",
        "- `tree.max_depth`: profundidad máxima del árbol de decisión.\n",
        "\n",
        "El modelo `TunedModel` se encarga de:\n",
        "1. Entrenar el pipeline completo con todas las combinaciones de parámetros posibles en el rango definido.\n",
        "2. Evaluar cada configuración con validación cruzada.\n",
        "3. Seleccionar el conjunto de hiperparámetros que produce el mejor resultado según la métrica elegida (en este caso, `cross_entropy`).\n",
        "\n",
        "A continuación se muestra el código que realiza este proceso.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "using MLJ, MLJModels, DataFrames, RDatasets, CategoricalArrays\n",
        "@load Standardizer pkg=MLJModels verbosity=0\n",
        "@load PCA pkg=MultivariateStats verbosity=0\n",
        "@load DecisionTreeClassifier pkg=DecisionTree verbosity=0\n",
        "\n",
        "# Instancias\n",
        "std  = Standardizer()\n",
        "pca  = PCA(maxoutdim=2)\n",
        "tree = DecisionTreeClassifier(max_depth=5)\n",
        "\n",
        "# Pipeline con NOMBRES explícitos de componentes\n",
        "pipe = MLJBase.Pipeline(\n",
        "    standardizer = std,\n",
        "    pca          = pca,\n",
        "    tree         = tree,\n",
        ")  # último es supervisado ⇒ pipeline de predicción (no hace falta 'operation')\n",
        "\n",
        "# Datos\n",
        "iris = RDatasets.dataset(\"datasets\", \"iris\")\n",
        "y = categorical(iris.Species)\n",
        "X = DataFrames.select(iris, DataFrames.Not(:Species))\n",
        "\n",
        "# Entrenar y evaluar rápidamente\n",
        "mach_pipe = machine(pipe, X, y) |> MLJ.fit!\n",
        "ŷ_pipe = MLJ.predict(mach_pipe, X)\n",
        "acc_pipe = accuracy(mode.(ŷ_pipe), y)\n",
        "println(\"Accuracy pipeline (entrenado en todo X): \", round(acc_pipe, digits=4))\n",
        "\n",
        "# Podemos también afinar hiperparámetros DENTRO del pipeline\n",
        "r_pca = range(pipe, :(MultivariateStats_.PCA.maxoutdim), lower=2, upper=4)\n",
        "r_tree = range(pipe, :(DecisionTree_.DecisionTreeClassifier.max_depth), lower=2, upper=8)\n",
        "\n",
        "tm_pipe = TunedModel(\n",
        "    model       = pipe,\n",
        "    tuning      = Grid(resolution=5),\n",
        "    resampling  = CV(nfolds=5, shuffle=true),\n",
        "    range       = [r_pca, r_tree],\n",
        "    measure     = cross_entropy,      # el árbol devuelve probs ⇒ métrica probabilística ok\n",
        "    acceleration = CPUThreads(),\n",
        "    check_measure = false,\n",
        ")\n",
        "\n",
        "mach_tm_pipe = machine(tm_pipe, X, y) |> MLJ.fit!\n",
        "best_pipe = fitted_params(mach_tm_pipe).best_model\n",
        "println(\"Mejor pipeline: \", best_pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "695ddcd9",
      "metadata": {},
      "source": [
        "El proceso de *tuning* recorre todas las combinaciones de hiperparámetros definidas en los rangos `r_pca` y `r_tree`, entrenando y evaluando el pipeline para cada una.  \n",
        "El resultado del ajuste se guarda en el objeto `mach_tm_pipe`, que contiene información sobre la búsqueda realizada y el modelo con mejor desempeño. Dentro de esto,\n",
        "\n",
        "* TunedModel automatiza la búsqueda de hiperparámetros.\n",
        "\n",
        "* Grid(resolution=5) significa que MLJ tomará 5 valores equiespaciados dentro de cada intervalo seleccionado de manera automática los puntos dentro de la los intervalos definidos. Si en lugar de un rango continuo defines un rango con valores discretos mediante values=[...], entonces resolution no se usa, y se prueban exactamente los valores indicados.\n",
        "\n",
        "* CV(nfolds=5) evalúa cada configuración con 5 particiones de validación cruzada.\n",
        "\n",
        "* El mejor pipeline se puede inspeccionar o volver a entrenar fácilmente con best_pipe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dab7c9f",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.10",
      "language": "julia",
      "name": "julia-1.10"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
